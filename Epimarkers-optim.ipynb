{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13017848,"sourceType":"datasetVersion","datasetId":8241949},{"sourceId":13018817,"sourceType":"datasetVersion","datasetId":8242635}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A spatial proteomics simplefied pipeline for marker-to-marker translation with leave-one-marker-out: \n\n*   Inputs: multiplexed tissue images with varying markers panels. Data was uploaded to Kaggle.  \n*   Preprocessing: normalize intensities by regressing each channel on available chromatin markers (DNA and core histones) and compute residuals, then apply PCA to project residuals into a 3-channel representation compatible with Resnet50. \n*   Encoder: pretrained Resnet50 (partially frozen) to extract morphological features. \n*   Decoder: U-Net with bilinear upsampling to reconstruct the left-out marker/channel.","metadata":{"editable":false}},{"cell_type":"markdown","source":"# imports","metadata":{"editable":false}},{"cell_type":"code","source":"!pip install pytorch_msssim\n!pip install imagecodecs\n!pip install torchmetrics\n!pip install clean-fid\n!pip install optuna\n\n#!pip install torch-fidelity","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport tifffile\nimport zipfile\nimport imagecodecs\nimport tempfile\nimport pickle\nimport json\nimport imageio\nimport sys\nimport psutil\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport gc\nimport time\nimport glob\nfrom collections import Counter, OrderedDict\nimport cv2\nimport random\nfrom scipy.stats import pearsonr\nfrom sklearn.decomposition import PCA, IncrementalPCA\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.model_selection import KFold\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.utils.parametrizations import weight_norm\nfrom torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\nfrom torch.amp import GradScaler, autocast\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision import models\nimport skimage.transform\nfrom pytorch_msssim import ms_ssim\nfrom tqdm import tqdm\nimport torchvision.utils as vutils\nfrom cleanfid import fid\nimport optuna\nfrom optuna.trial import Trial\n#from torchmetrics.image.fid import FrechetInceptionDistance\n\n\nimport matplotlib.pyplot as plt\nparams = {'axes.titlesize': 30,\n          'legend.fontsize': 16,\n          'figure.figsize': (16, 10),\n          'axes.labelsize': 16,\n          'axes.titlesize': 12,\n          'xtick.labelsize': 16,\n          'ytick.labelsize': 16,\n          'figure.titlesize': 30}\n\nplt.rcParams.update(params)\nplt.style.use('seaborn-v0_8-whitegrid')","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n#print(device)\n#print(torch.cuda.get_device_name(0))\n#print(f\"Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n#print(f\"Cached: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB\")\n#print(f\"Max allocated: {torch.cuda.max_memory_allocated(0)/1024**2:.2f} MB\")\n#!free -h","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"INPUT_CACHE_ROOT = \"/kaggle/input/your-notebook-output-files/cv_cache\"  # from the “Add Data” you attached\nWORK_CACHE_ROOT  = \"/kaggle/working/cv_cache\"\n\n# restore previous cache if present\nif os.path.exists(INPUT_CACHE_ROOT):\n    os.makedirs(WORK_CACHE_ROOT, exist_ok=True)\n    for src in glob.glob(os.path.join(INPUT_CACHE_ROOT, \"**/*\"), recursive=True):\n        if os.path.isfile(src):\n            dst = src.replace(INPUT_CACHE_ROOT, WORK_CACHE_ROOT, 1)\n            os.makedirs(os.path.dirname(dst), exist_ok=True)\n            shutil.copy2(src, dst)\n    print(f\"[init] Restored cache from {INPUT_CACHE_ROOT} -> {WORK_CACHE_ROOT}\")\nelse:\n    os.makedirs(WORK_CACHE_ROOT, exist_ok=True)\n    print(\"No previous cache found; starting fresh.\")","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# functions","metadata":{"editable":false}},{"cell_type":"code","source":"class ResNet50Encoder(nn.Module):\n    def __init__(self, in_channels=3):\n        super().__init__()\n        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = backbone.bn1\n        self.relu = backbone.relu\n        self.maxpool = backbone.maxpool\n        self.layer1 = backbone.layer1\n        self.layer2 = backbone.layer2\n        self.layer3 = backbone.layer3\n        self.layer4 = backbone.layer4\n        for param in backbone.parameters():\n            param.requires_grad = False\n            \n        for param in self.layer2.parameters():\n            param.requires_grad = True\n            \n        for param in self.layer3.parameters():\n            param.requires_grad = True\n            \n        for param in self.layer4.parameters():\n            param.requires_grad = True\n\n    def forward(self, x):\n        f0 = self.conv1(x)\n        f0 = self.bn1(f0)\n        f0 = self.relu(f0)\n        f0_pool = self.maxpool(f0)\n        f1 = self.layer1(f0_pool)\n        f2 = self.layer2(f1)\n        f3 = self.layer3(f2)\n        f4 = self.layer4(f3)\n        return f0, f1, f2, f3, f4\n\n\nclass UNetDecoder(nn.Module):\n    def __init__(self, out_channels=1, p=0.2):\n        super().__init__()\n        # Stage f4(2048) -> f3 scale (target 1024 ch)\n        self.conv4_1 = nn.Sequential(\n            nn.Conv2d(2048 + 1024, 1024, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n        self.conv4_2 = nn.Sequential(\n            nn.Conv2d(1024, 1024, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True),\n        )\n\n        # Stage -> f2 scale (target 512 ch)\n        self.conv3_1 = nn.Sequential(\n            nn.Conv2d(1024 + 512, 512, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n        self.conv3_2 = nn.Sequential(\n            nn.Conv2d(512, 512, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n        )\n\n        # Stage -> f1 scale (target 256 ch)\n        self.conv2_1 = nn.Sequential(\n            nn.Conv2d(512 + 256, 256, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n        self.conv2_2 = nn.Sequential(\n            nn.Conv2d(256, 256, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n        )\n\n        # Stage -> combine (f1 + f0) at f1 scale (target 64 ch)\n        self.conv1_1 = nn.Sequential(\n            nn.Conv2d(256 + 256 + 64, 64, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n        self.conv1_2 = nn.Sequential(\n            nn.Conv2d(64, 64, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n        )\n\n        # Final upsample \n        self.final_up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n\n        # Light head\n        self.up0 = nn.Sequential(\n            nn.Conv2d(64, 32, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n        )\n        self.final = weight_norm(nn.Conv2d(32, out_channels, 1))\n\n    def forward(self, skips):\n        f0, f1, f2, f3, f4 = skips \n\n        # ---- up4: f4 -> f3 scale ----\n        x = F.interpolate(f4, scale_factor=2, mode='bilinear', align_corners=False)\n        if x.shape[-2:] != f3.shape[-2:]:\n            f3 = F.interpolate(f3, size=x.shape[-2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, f3], dim=1)\n        x = self.conv4_1(x)\n        x = self.conv4_2(x)\n\n        # ---- up3: -> f2 scale ----\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n        if x.shape[-2:] != f2.shape[-2:]:\n            f2 = F.interpolate(f2, size=x.shape[-2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, f2], dim=1)\n        x = self.conv3_1(x)\n        x = self.conv3_2(x)\n\n        # ---- up2: -> f1 scale ----\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n        if x.shape[-2:] != f1.shape[-2:]:\n            f1 = F.interpolate(f1, size=x.shape[-2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, f1], dim=1)\n        x = self.conv2_1(x)\n        x = self.conv2_2(x)\n\n        # ---- up1: combine f1 & f0 at f1 scale ----\n        # f0 may need resize to f1 scale\n        if f0.shape[-2:] != f1.shape[-2:]:\n            f0 = F.interpolate(f0, size=f1.shape[-2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, f1, f0], dim=1)\n        x = self.conv1_1(x)\n        x = self.conv1_2(x)\n\n        # ---- final upsample + head ----\n        x = self.final_up(x) \n        x = self.up0(x)\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False) \n        x = torch.sigmoid(self.final(x))\n        return x\n\nclass ResNetUNet(nn.Module):\n    def __init__(self, in_channels=3):\n        super().__init__()\n        self.encoder = ResNet50Encoder(in_channels=in_channels)\n        self.decoder = UNetDecoder()\n\n    def forward(self, x):\n        skips = self.encoder(x)\n        return self.decoder(skips)\n\n# Wrap the lists in a custom Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, file_list, target_idx, control_markers_indices,\n                 regression_models, pca, pca_mean, pca_std, input_channels,\n                 n_components=3, cofactor=5.0, chunk_size=100_000):\n        self.file_list = file_list\n        self.target_idx = target_idx\n        self.control_markers_indices = control_markers_indices\n        self.regression_models = regression_models\n        self.pca = pca\n        self.pca_mean = pca_mean\n        self.pca_std = pca_std\n        self.input_channels = input_channels\n        self.n_components = n_components\n        self.cofactor = cofactor\n        self.chunk_size = chunk_size\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        file_path = self.file_list[idx]\n        x_tensor, y_tensor, _ = preprocess_image(\n            file_path,\n            self.target_idx,\n            self.control_markers_indices,\n            self.regression_models,\n            self.pca,\n            self.pca_mean,\n            self.pca_std,\n            self.input_channels,\n            self.n_components,\n            self.cofactor,\n            self.chunk_size\n        )\n        H, W = x_tensor.shape[1], x_tensor.shape[2]  \n        return x_tensor, y_tensor, (H, W)","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def to_hwc(img):\n    '''\n    Different libraries use different conventions.\n    - PyTorch: prefers CHW format (channels, height, width)\n    - TensorFlow/PIL/Matplotlib: prefer HWC format (height, width, channels)\n    The function ensures all images are consistently in HWC format for the preprocessing pipeline, regardless of how they were originally stored or loaded.\n    '''\n    if img.ndim == 2:\n        img = img[..., None]\n    if img.shape[0] < img.shape[1] and img.shape[0] < img.shape[2]:\n        img = np.transpose(img, (1, 2, 0))\n    return img.astype(np.float32, copy=False)\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\ndef fit_preprocessing(\n    train_files,\n    target_idx,\n    control_markers_indices,\n    n_components=3,\n    batch_size=100_000,\n    cofactor=5.0,\n    eps=1e-8):\n    \"\"\"\n    Fit channel-wise regressions and incremental PCA on residuals from IMC training images with lazy loading.\n    Returns: (regression_models, pca, pca_mean, pca_std, input_channels)\n    \"\"\"\n\n    # Discover channel setup from the first image\n    input_channels = []\n    img0 = to_hwc(tifffile.imread(train_files[0]))\n    print(f\"[info] example image shape: {img0.shape}\")\n    H, W, C = img0.shape\n    input_channels = [c for c in range(C) if c != target_idx and c not in control_markers_indices]\n    K = len(input_channels)\n    del img0; gc.collect()\n\n    if not input_channels:\n        print(f\"Warning: no inputs for target {target_idx} with controls {control_markers_indices}.\")\n        return None, None, None, None, input_channels\n\n    # 1. Fit regressions with SGDRegressor (partial_fit: true \"streaming\" mode)\n    regression_models = {}\n    first_pass = {}\n\n    for j in input_channels:\n        regression_models[j] = SGDRegressor(max_iter=1000, tol=1e-3)\n        first_pass[j] = True\n\n    for c, f in enumerate(train_files):\n        if c % int(len(train_files)/2) == 0 or c == len(train_files)-1:\n            print(f\"[info] extracting control and trg markers: {c+1} / {len(train_files)}\")\n        img = to_hwc(tifffile.imread(f))\n        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n        for j in input_channels:\n            y = img[..., j].reshape(-1)\n            if first_pass[j]:\n                regression_models[j].partial_fit(Xc, y)\n                first_pass[j] = False\n            else:\n                regression_models[j].partial_fit(Xc, y)\n        del img, Xc, y; gc.collect()\n\n    # 2. Incremental PCA on residuals (streamed, as before)\n    if n_components > K:\n        print(f\"n_components {n_components} > residual dim {K}; using {K}.\")\n        n_components = K\n    pca = IncrementalPCA(n_components=n_components)\n\n    for c, f in enumerate(train_files):\n        if c % int(len(train_files)/2) == 0 or c == len(train_files):\n            print(f\"[norm] fitting regression: {c+1} / {len(train_files)}\")\n\n        img = to_hwc(tifffile.imread(f))\n        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n        R = np.empty((Xc.shape[0], K), dtype=np.float32)\n        for k, j in enumerate(input_channels):\n            y = img[..., j].reshape(-1)\n            y_pred = regression_models[j].predict(Xc)\n            R[:, k] = y - y_pred.astype(np.float32, copy=False)\n        R = np.arcsinh(R / cofactor).astype(np.float32)\n        for s in range(0, R.shape[0], batch_size):\n            batch = R[s : s + batch_size]\n            pca.partial_fit(batch)\n        del img, Xc, R; gc.collect()\n\n    # 3. Compute mean/std of PCA space (streamed)\n    total = 0\n    sum_z = np.zeros(n_components, dtype=np.float64)\n    sumsq_z = np.zeros(n_components, dtype=np.float64)\n\n    for c, f in enumerate(train_files):\n        if c % int(len(train_files)/2) == 0 or c == len(train_files):\n            print(f\"[norm] normalization: {c+1} / {len(train_files)}\")\n\n        img = to_hwc(tifffile.imread(f))\n        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n        R = np.empty((Xc.shape[0], K), dtype=np.float32)\n        for k, j in enumerate(input_channels):\n            y = img[..., j].reshape(-1)\n            y_pred = regression_models[j].predict(Xc)\n            R[:, k] = y - y_pred.astype(np.float32, copy=False)\n        R = np.arcsinh(R / cofactor).astype(np.float32)\n        for s in range(0, R.shape[0], batch_size):\n            Z = pca.transform(R[s : s + batch_size]).astype(np.float32)\n            sum_z += Z.sum(axis=0)\n            sumsq_z += (Z * Z).sum(axis=0)\n            total += Z.shape[0]\n        del img, Xc, R, Z; gc.collect()\n\n    if total == 0:\n        print(\"Warning: no residuals seen for PCA stats; using zeros/ones.\")\n        pca_mean = np.zeros(n_components, dtype=np.float32)\n        pca_std = np.ones(n_components, dtype=np.float32) * eps\n    else:\n        pca_mean = (sum_z / total).astype(np.float32)\n        var = (sumsq_z / total) - (pca_mean.astype(np.float64) ** 2)\n        pca_std = (np.sqrt(np.maximum(var, 0.0)) + eps).astype(np.float32)\n\n    # Print variance captured by PCs if possible\n    if hasattr(pca, \"explained_variance_ratio_\") and pca.explained_variance_ratio_ is not None:\n        pct = pca.explained_variance_ratio_[:n_components].sum() * 100.0\n        print(f\"[norm] PCA projection to {n_components}D captures {pct:.2f}% variance\")\n\n    return regression_models, pca, pca_mean, pca_std, input_channels\n\ndef preprocess_image(\n    file_path,\n    target_idx,\n    control_markers_indices,\n    regression_models,\n    pca,\n    pca_mean,\n    pca_std,\n    input_channels,\n    n_components=3,\n    cofactor=5.0,\n    chunk_size=100_000):\n    \"\"\"\n    Load and preprocess a single IMC image lazily by:\n    - loading image,\n    - normalizing target,\n    - computing residuals from regression,\n    - arcsinh transform,\n    - PCA transform in batches,\n    - Z-score normalization of PCA features,\n    - return PyTorch tensors for model input.\n    \"\"\"\n\n    img = tifffile.imread(file_path)\n    img = to_hwc(img)\n    H, W, C = img.shape\n    filename = os.path.basename(file_path)\n\n    # Normalize target channel intensities with arcsinh and min-max\n    target_data = img[..., target_idx]\n    y_arc = np.arcsinh(target_data / cofactor).astype(np.float32)\n    y_min, y_max = y_arc.min(), y_arc.max()\n    y_norm = (y_arc - y_min) / (y_max - y_min + 1e-8)\n    y_tensor = torch.from_numpy(y_norm[None, ...]).float()  # (1, H, W)\n\n    # Prepare control channel matrix\n    n_ctrl = len(control_markers_indices)\n    K = len(input_channels)\n    Xc = img[..., control_markers_indices].reshape(-1, n_ctrl)           # (N, n_ctrl)\n    Yin = np.stack([img[..., j].reshape(-1) for j in input_channels], 1)  # (N, K)\n\n    # Stack regression coef and intercept for vectorized prediction\n    B = np.stack([regression_models[j].coef_ for j in input_channels], axis=-1).astype(np.float32)  # (n_ctrl, K)\n    b = np.array([regression_models[j].intercept_ for j in input_channels], dtype=np.float32)       # (K,)\n    b = b.flatten()\n\n    # Predict residuals Y - regression(X)\n    Yhat = Xc @ B + b                                                # (N, K)\n    R = Yin - Yhat\n    R = np.arcsinh(R / cofactor).astype(np.float32)\n\n    # PCA transform in chunks, for low memory\n    N = R.shape[0]\n    Z = np.empty((N, n_components), dtype=np.float32)\n    for s in range(0, N, chunk_size):\n        e = s + chunk_size\n        Z[s:e] = pca.transform(R[s:e])\n\n    # Z-score normalize PCA components\n    Z = (Z - pca_mean) / (pca_std + 1e-8)\n    Z = Z.reshape(H, W, n_components)\n\n    # Convert PCA tensor to channel-first for PyTorch\n    x_tensor = torch.from_numpy(Z).permute(2, 0, 1).contiguous().float()  # (C, H, W)\n\n    return x_tensor, y_tensor, filename\n\n\ndef apply_preprocessing(\n    files,\n    target_idx,\n    control_markers_indices,\n    regression_models,\n    pca,\n    pca_mean,\n    pca_std,\n    input_channels,\n    n_components=3,\n    cofactor=5.0,\n    chunk_size=100_000):\n    \n    X_pca_tensor, Y_norm_list, filenames = [], [], []\n\n    for c, f in enumerate(files):\n        if c % int(len(files)/2) == 0 or c == len(files):\n            print(f\"[norm] applying preprocessing: {c+1} / {len(files)}\")\n\n        x_tensor, y_tensor, filename = preprocess_image(\n            f, target_idx, control_markers_indices, regression_models, pca,\n            pca_mean, pca_std, input_channels, n_components, cofactor, chunk_size\n        )\n        X_pca_tensor.append(x_tensor)\n        Y_norm_list.append(y_tensor)\n        filenames.append(filename)\n    return X_pca_tensor, Y_norm_list, filenames\n\ndef pad_collate(batch):\n    \"\"\"\n    Pads all tensors in a batch to the largest size.\n    Also returns original sizes for cropping.\n    \"\"\"\n    X_list, Y_list, original_sizes = zip(*batch)\n\n    max_H = max([x.shape[1] for x in X_list])\n    max_W = max([x.shape[2] for x in X_list])\n\n    padded_X_list = []\n    padded_Y_list = []\n\n    for x_tensor, y_tensor in zip(X_list, Y_list):\n        pad_H = max_H - x_tensor.shape[1]\n        pad_W = max_W - x_tensor.shape[2]\n\n        padded_X = F.pad(x_tensor, (0, pad_W, 0, pad_H))\n        padded_Y = F.pad(y_tensor, (0, pad_W, 0, pad_H))\n\n        padded_X_list.append(padded_X)\n        padded_Y_list.append(padded_Y)\n\n\n    return torch.stack(padded_X_list), torch.stack(padded_Y_list), original_sizes\n\ndef train_model(model, train_loader, val_loader, device, title,\n                config,\n                epochs=50,\n                huber_beta=1.0,\n                grad_clip=1.0,\n                use_amp=True,\n                patience=10,\n                save_path=\"best_model.pth\",\n                dataset=None,\n                ):\n\n    \"\"\"\n    Loss = alpha * Huber(y_hat, y) + (1 - alpha) * (1 - SSIM(y_hat_norm, y_norm)).\n    - Huber is on intensities.\n    - SSIM is per-image min-max normalized to [0,1].\n    \"\"\"\n\n    model.to(device)\n    \n    lr = config.get('lr')\n    alpha = config.get('alpha')\n    \n    opt = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=1e-5)\n    \n    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.7, patience=3)\n    scaler = GradScaler(enabled=use_amp)\n\n    train_losses, val_losses = [], []\n    best_val, best_state, best_epoch = float(\"inf\"), None, None\n    no_improve = 0\n    epsilon = 1e-8\n\n    for epoch in range(epochs):\n        # Training loop unchanged\n        model.train()\n        running = 0.0\n        for x, y, original_sizes in train_loader:\n            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n            B, _, H_padded, W_padded = x.shape  # Padded dimensions\n\n            opt.zero_grad(set_to_none=True)\n            with autocast(device_type='cuda', enabled=use_amp):\n                yhat = model(x)\n\n                hub_sum = 0.0\n                ssim_sum = 0.0\n                for i in range(B):\n                    h, w = original_sizes[i]\n                    y_i = y[i:i+1, :, :h, :w]  # Ground truth (cropped)\n                    yhat_i = yhat[i:i+1, :, :h, :w]  # Prediction (cropped)\n\n                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n                    hub_sum += hub_i\n\n                    y_min, y_max = y_i.min().detach(), y_i.max().detach()\n                    yh_min, yh_max = yhat_i.min().detach(), yhat_i.max().detach()\n                    y_n = (y_i - y_min) / (y_max - y_min + epsilon)\n                    yhat_n = (yhat_i - yh_min) / (yh_max - yh_min + epsilon)\n                    ssim_sum += (1.0 - ms_ssim(yhat_n, y_n, data_range=1.0))\n\n                hub_mean = hub_sum / B\n                ssim_mean = ssim_sum / B\n\n                loss = alpha * hub_mean + (1 - alpha) * ssim_mean\n\n            scaler.scale(loss).backward()\n            if grad_clip is not None:\n                scaler.unscale_(opt)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n            scaler.step(opt)\n            scaler.update()\n\n            running += loss.item() * B\n\n        train_loss = running / len(train_loader.dataset)\n        train_losses.append(train_loss)\n\n        # Validation loop with robust error checking and batch skipping\n        model.eval()\n        val_running = 0.0\n        valid_batches = 0\n        with torch.no_grad(), autocast(device_type='cuda', enabled=use_amp):\n            for batch_idx, (x, y, original_sizes) in enumerate(val_loader):\n                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n                B, _, H_padded, W_padded = x.shape  # Padded dimensions\n\n                yhat = model(x)\n\n                hub_sum = 0.0\n                ssim_sum = 0.0\n                skip_batch = False\n\n                for i in range(B):\n                    h, w = original_sizes[i]\n                    y_i = y[i:i+1, :, :h, :w]\n                    yhat_i = yhat[i:i+1, :, :h, :w]\n\n                    # Clamp predictions between 0 and 1 for numerical stability\n                    yhat_i = torch.clamp(yhat_i, min=0.0, max=1.0)\n\n                    y_min, y_max = y_i.min(), y_i.max()\n                    yh_min, yh_max = yhat_i.min(), yhat_i.max()\n                    denom_y = (y_max - y_min).abs() + epsilon\n                    denom_yh = (yh_max - yh_min).abs() + epsilon\n\n                    if denom_y < epsilon or denom_yh < epsilon:\n                        #print(f\"Note: validation batch {batch_idx}, sample {i} skipped due to near-constant values\")\n                        skip_batch = True\n                        break\n\n                    y_n = (y_i - y_min) / denom_y\n                    yhat_n = (yhat_i - yh_min) / denom_yh\n\n                    ssim_val = ssim(yhat_n, y_n, data_range=1.0)\n                    if torch.isnan(ssim_val) or torch.isinf(ssim_val):\n                        #print(f\"Note: validation batch {batch_idx}, sample {i} SSIM returned NaN or Inf, skipping batch\")\n                        skip_batch = True\n                        break\n\n                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n                    if torch.isnan(hub_i) or torch.isinf(hub_i):\n                        #print(f\"Note: validation batch {batch_idx}, sample {i} Huber loss returned NaN or Inf, skipping batch\")\n                        skip_batch = True\n                        break\n\n                    hub_sum += hub_i\n                    ssim_sum += (1.0 - ssim_val)\n\n                if skip_batch:\n                    continue  # Skip entire batch aggregation\n\n                val_loss_batch = (alpha * hub_sum + (1 - alpha) * ssim_sum) / B\n                if torch.isnan(val_loss_batch) or torch.isinf(val_loss_batch):\n                    #print(f\"Note: validation batch {batch_idx} computed val_loss_batch as NaN or Inf, skipping\")\n                    continue\n\n                val_running += float(val_loss_batch) * B\n                valid_batches += B\n\n        if valid_batches > 0:\n            val_loss = val_running / valid_batches\n        else:\n            val_loss = float('nan')\n\n        val_losses.append(val_loss)\n        sched.step(val_loss)\n\n        print(f\"Epoch {epoch+1:>3d} | Train {train_loss:.3f} | Val {val_loss:.3f}\")\n\n        # ---- Early stopping ----\n        if val_loss + 1e-6 < best_val:\n            best_val, best_epoch = val_loss, epoch + 1\n            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n            no_improve = 0\n            print(f\"  ↳ New best val={val_loss:.3f} at epoch {best_epoch}\")\n            if save_path:\n                torch.save(best_state, save_path)\n                print(f\"  ↳ Saved checkpoint to {save_path}\")\n        else:\n            no_improve += 1\n            print(f\"  ↳ No improvement ({no_improve}/{patience} patience)\")\n            if patience is not None and no_improve >= patience:\n                print(f\"--Early stopping at epoch {epoch+1}. Best epoch was {best_epoch} with val={best_val:.3f}\")\n                break\n\n    # Restore best weights\n    if best_state is not None:\n        model.load_state_dict(best_state)\n        print(f\"--Restored model weights from epoch {best_epoch} (val={best_val:.3f})\")\n\n    # Plot losses\n    plt.figure(figsize=(8, 5))\n    plt.plot(range(1, len(train_losses)+1), train_losses, marker='o', label='Train')\n    plt.plot(range(1, len(val_losses)+1), val_losses, marker='s', label='Val')\n    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'Marker: {title}')\n    plt.legend(); plt.grid(True); plt.show()\n\n    return train_losses, val_losses\n    \ndef visualize_prediction(model, dataset, device, indices=None, target_channel=0, name=\"comparison_grid\"):\n    \"\"\"\n    Show & save 5 example pairs (GT | Pred). \n    \"\"\"\n\n    model = model.to(device)\n    model.eval()\n\n    if indices is None:\n        k = 15\n        # sample without replacement; if len<5 just take range(k)\n        indices = random.sample(range(len(dataset)), k) if len(dataset) >= k else list(range(len(dataset)))\n\n    # build figure\n    n = len(indices)\n    fig, axs = plt.subplots(n, 2, figsize=(8, 4 * n))\n    if n == 1:\n        axs = np.expand_dims(axs, axis=0)  # make it 2D\n\n    with torch.no_grad():\n        for row, idx in enumerate(indices):\n            x_tensor, y_tensor, _ = dataset[idx]\n            x_tensor = x_tensor.unsqueeze(0).to(device)\n            y_tensor = y_tensor.unsqueeze(0).to(device)\n\n            y_pred = model(x_tensor)\n\n            # crop out tile borders to remove padding artifacts\n            crop_margin = 64  # try 32 or 64 depending on your tile size\n            _, _, H, W = y_pred.shape\n            y_pred = y_pred[:, :, crop_margin:H - crop_margin, crop_margin:W - crop_margin]\n            \n            # also crop ground truth to match\n            y_tensor = y_tensor[:, :, crop_margin:H - crop_margin, crop_margin:W - crop_margin]\n            \n            \n            # to numpy, select channel, [0,1] normalize\n            y_true_np = y_tensor.squeeze().detach().cpu().numpy()\n            y_pred_np = y_pred.squeeze().detach().cpu().numpy()\n            if y_true_np.ndim == 3:\n                y_true_np = y_true_np[target_channel]\n            if y_pred_np.ndim == 3:\n                y_pred_np = y_pred_np[target_channel]\n            y_true_np = (y_true_np - y_true_np.min()) / (y_true_np.max() - y_true_np.min() + 1e-8)\n            y_pred_np = (y_pred_np - y_pred_np.min()) / (y_pred_np.max() - y_pred_np.min() + 1e-8)\n\n            axs[row, 0].imshow(y_true_np, cmap=\"inferno\")\n            axs[row, 0].set_title(f\"Ground Truth (idx {idx})\")\n            axs[row, 0].axis(\"off\")\n\n            axs[row, 1].imshow(y_pred_np, cmap=\"inferno\")\n            axs[row, 1].set_title(\"Prediction\")\n            axs[row, 1].axis(\"off\")\n\n    fig.suptitle(f\"{name}\", fontsize=14)\n    fig.tight_layout(rect=[0, 0, 1, 0.97])\n\n    # always save (headless-friendly), then show if a display exists\n    out_path = f\"comparison_grid_{name}.png\"\n    fig.savefig(out_path, dpi=400, bbox_inches=\"tight\")\n\n    try:\n        plt.show()  # no-op in headless; displays in Kaggle notebooks\n    finally:\n        plt.close(fig)\n\n    print(f\"[vis] Saved comparison figure to: {out_path}\")\n\ndef smart_load_state_dict(model, state, strict=True):\n    \n    is_dp = isinstance(model, torch.nn.DataParallel)\n    has_module = all(k.startswith(\"module.\") for k in state.keys())\n    if is_dp and not has_module:\n        return model.module.load_state_dict(state, strict=strict)          # add prefix implicitly\n    if (not is_dp) and has_module:\n        state = {k.replace(\"module.\", \"\", 1): v for k, v in state.items()}  # strip prefix\n        return model.load_state_dict(state, strict=strict)\n    target = model.module if is_dp else model\n    return target.load_state_dict(state, strict=strict)\n\ndef train_model_with_config(\n    model, train_loader, val_loader, device, title,\n    config: dict,\n    save_path=\"best_model.pth\"):\n    \"\"\"\n    Modified training function that accepts a config dictionary.\n    Returns best validation loss for optimization.\n    \"\"\"\n\n    model.to(device)\n\n    # Extract hyperparameters from config\n    lr = config.get('lr', 1e-4)\n    alpha = config.get('alpha', 0.8)\n    huber_beta = config.get('huber_beta', 1.0)\n    weight_decay = config.get('weight_decay', 1e-5)\n    grad_clip = config.get('grad_clip', 1.0)\n    scheduler_patience = config.get('scheduler_patience', 5)\n    scheduler_factor = config.get('scheduler_factor', 0.7)\n    epochs = config.get('epochs', 50)\n    early_stop_patience = config.get('early_stop_patience', 10)\n\n    # Setup optimizer and scheduler\n    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        opt, mode=\"min\", factor=scheduler_factor, patience=scheduler_patience\n    )\n    scaler = GradScaler(enabled=True)\n\n    best_val = float(\"inf\")\n    no_improve = 0\n    epsilon = 1e-8\n\n    for epoch in range(epochs):\n        # Training\n        model.train()\n        running = 0.0\n        for x, y, original_sizes in train_loader:\n            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n            B = x.shape[0]\n\n            opt.zero_grad(set_to_none=True)\n            with autocast(device_type='cuda', enabled=True):\n                yhat = model(x)\n\n                hub_sum = 0.0\n                ssim_sum = 0.0\n                for i in range(B):\n                    h, w = original_sizes[i]\n                    y_i = y[i:i+1, :, :h, :w]\n                    yhat_i = yhat[i:i+1, :, :h, :w]\n\n                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n                    hub_sum += hub_i\n\n                    y_min, y_max = y_i.min().detach(), y_i.max().detach()\n                    yh_min, yh_max = yhat_i.min().detach(), yhat_i.max().detach()\n                    y_n = (y_i - y_min) / (y_max - y_min + epsilon)\n                    yhat_n = (yhat_i - yh_min) / (yh_max - yh_min + epsilon)\n                    ssim_sum += (1.0 - ssim(yhat_n, y_n, data_range=1.0))\n\n                hub_mean = hub_sum / B\n                ssim_mean = ssim_sum / B\n                loss = alpha * hub_mean + (1 - alpha) * ssim_mean\n\n            scaler.scale(loss).backward()\n            if grad_clip is not None:\n                scaler.unscale_(opt)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n            scaler.step(opt)\n            scaler.update()\n            running += loss.item() * B\n\n        train_loss = running / len(train_loader.dataset)\n\n        # Validation\n        model.eval()\n        val_running = 0.0\n        valid_batches = 0\n        with torch.no_grad(), autocast(device_type='cuda', enabled=True):\n            for x, y, original_sizes in val_loader:\n                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n                B = x.shape[0]\n                yhat = model(x)\n\n                hub_sum = 0.0\n                ssim_sum = 0.0\n                skip_batch = False\n\n                for i in range(B):\n                    h, w = original_sizes[i]\n                    y_i = y[i:i+1, :, :h, :w]\n                    yhat_i = yhat[i:i+1, :, :h, :w]\n                    yhat_i = torch.clamp(yhat_i, min=0.0, max=1.0)\n\n                    y_min, y_max = y_i.min(), y_i.max()\n                    yh_min, yh_max = yhat_i.min(), yhat_i.max()\n                    denom_y = (y_max - y_min).abs() + epsilon\n                    denom_yh = (yh_max - yh_min).abs() + epsilon\n\n                    if denom_y < epsilon or denom_yh < epsilon:\n                        skip_batch = True\n                        break\n\n                    y_n = (y_i - y_min) / denom_y\n                    yhat_n = (yhat_i - yh_min) / denom_yh\n\n                    ssim_val = ssim(yhat_n, y_n, data_range=1.0)\n                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n\n                    if torch.isnan(ssim_val) or torch.isinf(ssim_val) or torch.isnan(hub_i):\n                        skip_batch = True\n                        break\n\n                    hub_sum += hub_i\n                    ssim_sum += (1.0 - ssim_val)\n\n                if not skip_batch:\n                    val_loss_batch = (alpha * hub_sum + (1 - alpha) * ssim_sum) / B\n                    if not (torch.isnan(val_loss_batch) or torch.isinf(val_loss_batch)):\n                        val_running += float(val_loss_batch) * B\n                        valid_batches += B\n\n        val_loss = val_running / valid_batches if valid_batches > 0 else float('nan')\n        sched.step(val_loss)\n\n        # Early stopping\n        if val_loss + 1e-6 < best_val:\n            best_val = val_loss\n            no_improve = 0\n            if save_path:\n                torch.save(model.state_dict(), save_path)\n        else:\n            no_improve += 1\n            if no_improve >= early_stop_patience:\n                print(f\"Early stop at epoch {epoch+1}, best val={best_val:.4f}\")\n                break\n\n        # Report progress every 5 epochs\n        if epoch % 5 == 0:\n            print(f\"Epoch {epoch+1}/{epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n\n    return best_val\n\n\ndef objective(trial: Trial, train_loader, val_loader, device, model_fn, title):\n    \"\"\"\n    Optuna objective function for hyperparameter search.\n\n    Args:\n        trial: Optuna trial object\n        train_loader: Training data loader\n        val_loader: Validation data loader\n        device: PyTorch device\n        model_fn: Function that returns a fresh model instance\n        title: Experiment title\n\n    Returns:\n        best_val_loss: Best validation loss achieved\n    \"\"\"\n\n    # Sample hyperparameters\n    config = {\n        'lr': trial.suggest_float('lr', 3e-5, 5e-4, log=True),\n        'alpha': trial.suggest_float('alpha', 0.5, 0.99),\n        'epochs': 20,  # Faster trials during optimization\n\n    }\n\n    # Create fresh model\n    model = model_fn()\n\n    # Train and get best validation loss\n    try:\n        best_val = train_model_with_config(\n            model, train_loader, val_loader, device, title,\n            config=config,\n            save_path=f\"trial_{trial.number}_best.pth\"\n        )\n        return best_val\n    except Exception as e:\n        print(f\"Trial {trial.number} failed: {e}\")\n        return float('inf')\n\n\ndef run_hyperparameter_search(\n    train_loader, \n    val_loader, \n    device, \n    model_fn,\n    title,\n    n_trials=20,\n    study_name=\"stain_translation_opt\"):\n    \"\"\"\n    Run Optuna hyperparameter optimization.\n\n    Args:\n        train_loader: Training data loader\n        val_loader: Validation data loader\n        device: PyTorch device\n        model_fn: Function that returns a fresh model instance (e.g., lambda: ResNet50UNet(...))\n        title: Experiment title\n        n_trials: Number of optimization trials\n        study_name: Name for the Optuna study\n\n    Returns:\n        study: Optuna study object with results\n    \"\"\"\n\n    # Create study\n    study = optuna.create_study(\n        direction='minimize',\n        study_name=study_name,\n        sampler=optuna.samplers.TPESampler(seed=42)\n    )\n\n    # Run optimization\n    study.optimize(\n        lambda trial: objective(trial, train_loader, val_loader, device, model_fn, title),\n        n_trials=n_trials,\n        show_progress_bar=True\n    )\n\n    # Print results\n    print(\"\\n\" + \"=\"*80)\n    print(\"HYPERPARAMETER OPTIMIZATION RESULTS\")\n    print(\"=\"*80)\n    print(f\"Best trial: {study.best_trial.number}\")\n    print(f\"Best validation loss: {study.best_value:.6f}\")\n    print(f\"\\nBest hyperparameters:\")\n    for key, value in study.best_params.items():\n        print(f\"  {key}: {value}\")\n\n    # Plot optimization history\n    try:\n        fig = optuna.visualization.plot_optimization_history(study)\n        fig.show()\n    except:\n        pass\n\n    # Plot parameter importances\n    try:\n        fig = optuna.visualization.plot_param_importances(study)\n        fig.show()\n    except:\n        pass\n\n    return study\n\n\ndef optimize_for_marker(path, target_idx, control_markers_indices, title, \n                        data_name, sample_fraction=0.2): \n    \"\"\"Run optimization on fold 1, return best hyperparameters.\"\"\"\n    \n    n_components = 3\n    cofactor = 5.0\n    batch_size = 2\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    \n    all_files = sorted([os.path.join(path, f) for f in os.listdir(path) \n                       if f.endswith(('.tif', '.tiff'))])\n    \n    # Simple 75/25 train/val split\n    random.seed(42)\n    random.shuffle(all_files)\n    split_idx = int(0.75 * len(all_files))\n    train_files = all_files[:split_idx]\n    val_files = all_files[split_idx:]\n    \n    print(f\"[split] {len(train_files)} train, {len(val_files)} val\")\n\n    # Fit preprocessing\n    print(f\"[fitting] Running preprocessing...\")\n    regression_models, pca, pca_mean, pca_std, input_channels = fit_preprocessing(\n        train_files, target_idx, control_markers_indices, \n        n_components=n_components, cofactor=cofactor\n    )\n    \n    # Subsample training data (for speed)\n    n_train_samples = max(50, int(len(train_files) * sample_fraction))\n    train_files_subset = random.sample(train_files, n_train_samples)\n    \n    print(f\"[info] Using {len(train_files_subset)} train samples (20%)\")\n    print(f\"[info] Using {len(val_files)} val samples (100%)\")\n\n    # Apply preprocessing\n    X_train, Y_train, _ = apply_preprocessing(\n        train_files_subset,  \n        target_idx, control_markers_indices,\n        regression_models, pca, pca_mean, pca_std, input_channels,\n        n_components=n_components, cofactor=cofactor\n    )\n    \n    X_val, Y_val, _ = apply_preprocessing(\n        val_files,\n        target_idx, control_markers_indices,\n        regression_models, pca, pca_mean, pca_std, input_channels,\n        n_components=n_components, cofactor=cofactor\n    )\n    \n    train_dataset = list(zip(X_train, Y_train, [x.shape[1:] for x in X_train]))\n    val_dataset = list(zip(X_val, Y_val, [x.shape[1:] for x in X_val]))\n    \n    train_loader = DataLoader(train_dataset, batch_size=batch_size, \n                             shuffle=True, collate_fn=pad_collate)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, \n                           shuffle=False, collate_fn=pad_collate)\n    \n    # Optimization\n    def create_model():\n        return ResNetUNet(in_channels=n_components)\n    \n    study = run_hyperparameter_search(\n        train_loader, val_loader, device, create_model,\n        title=title, n_trials=10, study_name=f\"{data_name}_{title}_opt\"\n    )\n    \n    return study.best_params\n    ","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main(\n    path: str,\n    target_idx: int,\n    control_markers_indices: list,\n    title: str = \"Unspecified\",\n    hyperparams: dict = None,\n    n_splits: int = 4,\n    batch_size: int = 2,\n    device: str = None,\n    data_name: str = None,\n    cache_dir: str = \"./cv_cache\",\n    resume: bool = True,\n    n_components: int = 3,\n    cofactor: float = 5.0,\n    ):\n    \n        \n    os.makedirs(cache_dir, exist_ok=True)\n    set_seed(42)\n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    extract_folder = path\n    all_files = sorted(\n        [os.path.join(extract_folder, f) for f in os.listdir(extract_folder) if f.endswith(('.tif', '.tiff'))]\n    )\n    if len(all_files) < n_splits:\n        raise ValueError(f\"Number of files ({len(all_files)}) must be >= number of CV splits ({n_splits})\")\n\n    splits_path = os.path.join(cache_dir, f\"cv_splits_{data_name}_{title}_{n_splits}fold.pkl\")\n    if resume and os.path.exists(splits_path):\n        with open(splits_path, \"rb\") as f:\n            splits = pickle.load(f)  # list of tuples: (train_files, val_files)\n        print(f\"[init] Loaded fixed CV splits from {splits_path}\")\n    else:\n        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n        splits = []\n        for tr_idx, va_idx in kf.split(all_files):\n            train_files = [all_files[i] for i in tr_idx]\n            val_files   = [all_files[i] for i in va_idx]\n            splits.append((train_files, val_files))\n        with open(splits_path, \"wb\") as f:\n            pickle.dump(splits, f)\n        print(f\"[init] Saved fixed CV splits to {splits_path}\")\n\n    rmse_folds, pearson_folds, fid_folds = [], [], []\n    best_rmse, best_fold_idx, best_model_path = None, None, None\n\n    for fold_idx, (train_files, val_files) in enumerate(splits, 1):\n        print(f\"[cv] Fold {fold_idx}/{n_splits}, marker {title} ######\")\n        torch.cuda.empty_cache()\n        gc.collect()\n        \n        fold_tag = f\"{data_name}_{title}_fold{fold_idx}\"\n        preproc_pkl = os.path.join(cache_dir, f\"preproc_{fold_tag}.pkl\")\n        ckpt_path   = os.path.join(cache_dir, f\"model_{fold_tag}.pth\")\n        metrics_js  = os.path.join(cache_dir, f\"metrics_{fold_tag}.json\")\n\n        if resume and os.path.exists(preproc_pkl):\n            with open(preproc_pkl, \"rb\") as f:\n                reg_models, pca, pca_mean, pca_std, input_channels = pickle.load(f)\n            print(f\"[init] Loaded preprocessing for fold {fold_idx} from {preproc_pkl}\")\n        else:\n            reg_models, pca, pca_mean, pca_std, input_channels = fit_preprocessing(\n                train_files, target_idx, control_markers_indices, n_components=n_components, cofactor=cofactor\n            )\n            with open(preproc_pkl, \"wb\") as f:\n                pickle.dump((reg_models, pca, pca_mean, pca_std, input_channels), f)\n            print(f\"[cache] Saved preprocessing for fold {fold_idx} to {preproc_pkl}\")\n\n        train_dataset = CustomDataset(\n            train_files, target_idx, control_markers_indices,\n            reg_models, pca, pca_mean, pca_std, input_channels,\n            n_components=n_components, cofactor=cofactor\n        )\n        val_dataset = CustomDataset(\n            val_files, target_idx, control_markers_indices,\n            reg_models, pca, pca_mean, pca_std, input_channels,\n            n_components=n_components, cofactor=cofactor\n        )\n\n        train_loader = DataLoader(\n            train_dataset, batch_size=batch_size, shuffle=True,\n            collate_fn=pad_collate, num_workers=2, pin_memory=True\n        )\n        val_loader = DataLoader(\n            val_dataset, batch_size=batch_size, shuffle=False,\n            collate_fn=pad_collate, num_workers=2, pin_memory=True\n        )\n\n        model = ResNetUNet(in_channels=n_components).to(device)\n            \n        # (Optional) channels_last improves memory use:\n        model = model.to(memory_format=torch.channels_last)\n\n        config = {\n            'lr': hyperparams['lr'],\n            'alpha': hyperparams['alpha'],\n        }\n        \n        if torch.cuda.device_count() > 1:\n            model = torch.nn.DataParallel(model)\n\n        if resume and os.path.exists(ckpt_path):\n            print(f\"[resume] Found existing checkpoint for fold {fold_idx}, loading...\")\n            state = torch.load(ckpt_path, map_location=device)\n            smart_load_state_dict(model, state, strict=True)\n            print(f\"[resume] Loaded model checkpoint for fold {fold_idx} from {ckpt_path}\")\n        else:\n            print(f\"[train] Training model for fold {fold_idx} ...\")\n            train_model(\n                model, train_loader, val_loader, device,\n                config=config, \n                title=f\"{title} fold {fold_idx}\", \n                dataset=data_name,\n            )\n            # save without DP prefix\n            to_save = model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict()\n            torch.save(to_save, ckpt_path)\n            print(f\"[cache] Saved model checkpoint to {ckpt_path}\")\n\n        # ---- (3) Metrics: compute or load ----\n        if resume and os.path.exists(metrics_js):\n            with open(metrics_js, \"r\") as f:\n                fold_metrics = json.load(f)\n            print(f\"[resume] Loaded metrics for fold {fold_idx} from {metrics_js}\")\n            rmse_mean = fold_metrics[\"RMSE_mean_fold\"]\n            pearson_v = fold_metrics[\"Pearson_fold\"]\n            fid_val   = fold_metrics[\"FID_fold\"]\n        else:\n            # Evaluate on val set (same as your original, but streaming FID save)\n            model.eval()\n            rmse_list = []\n            all_y_pred_pixels, all_y_true_pixels = [], []\n\n            # For FID: write resized images on the fly to temp dirs to avoid RAM spikes\n            with tempfile.TemporaryDirectory() as pred_dir, tempfile.TemporaryDirectory() as true_dir:\n                idx_img = 0\n                with torch.no_grad(), autocast(device_type='cuda', enabled=True):\n                    for x, y, _ in val_loader:\n                        x = x.to(device, non_blocking=True).to(memory_format=torch.channels_last)\n                        y = y.to(device, non_blocking=True)\n                        yhat = model(x)\n                        _, _, H, W = y.shape\n                        yhat_cropped = yhat[:, :, :H, :W].clamp(0, 1)\n\n                        # RMSE (per batch)\n                        mse_val = F.mse_loss(yhat_cropped, y).item()\n                        rmse_list.append(np.sqrt(mse_val))\n\n                        # Pearson pixels (accumulate)\n                        yhat_flat = yhat_cropped.detach().cpu().numpy().ravel()\n                        y_flat    = y.detach().cpu().numpy().ravel()\n                        all_y_pred_pixels.append(yhat_flat)\n                        all_y_true_pixels.append(y_flat)\n\n                        # FID: save normalized RGB versions (repeat if single channel)\n                        if yhat_cropped.shape[1] == 1:\n                            y_true_img = y.repeat(1, 3, 1, 1).float()\n                            y_pred_img = yhat_cropped.repeat(1, 3, 1, 1).float()\n                        else:\n                            y_true_img, y_pred_img = y.float(), yhat_cropped.float()\n\n                        # per-image min-max → [0,1]\n                        for b in range(y_true_img.size(0)):\n                            gt = y_true_img[b]\n                            pr = y_pred_img[b]\n                            gt = (gt - gt.min()) / (gt.max() - gt.min() + 1e-8)\n                            pr = (pr - pr.min()) / (pr.max() - pr.min() + 1e-8)\n\n                            gt_np = gt.permute(1,2,0).cpu().numpy()\n                            pr_np = pr.permute(1,2,0).cpu().numpy()\n\n                            # resize to 512×512×3 and save uint8\n                            gt_np = skimage.transform.resize(gt_np, (512, 512, 3), anti_aliasing=True, mode='reflect')\n                            pr_np = skimage.transform.resize(pr_np, (512, 512, 3), anti_aliasing=True, mode='reflect')\n                            gt_u8 = (gt_np * 255).clip(0,255).astype(np.uint8)\n                            pr_u8 = (pr_np * 255).clip(0,255).astype(np.uint8)\n\n                            imageio.imwrite(os.path.join(true_dir, f\"{idx_img}.png\"), gt_u8)\n                            imageio.imwrite(os.path.join(pred_dir, f\"{idx_img}.png\"), pr_u8)\n                            idx_img += 1\n\n                # compute FID\n                fid_val = fid.compute_fid(pred_dir, true_dir, \n                                          batch_size=batch_size, device=device, mode=\"clean\", verbose=False)\n            print(f\"[res] FID = {fid_val:.1f}\")\n\n            all_y_pred_pixels = np.concatenate(all_y_pred_pixels)\n            all_y_true_pixels = np.concatenate(all_y_true_pixels)\n            pearson_v, _ = pearsonr(all_y_pred_pixels, all_y_true_pixels)\n            rmse_mean = float(np.mean(rmse_list))\n\n            # cache metrics\n            fold_metrics = {\n                \"marker\": title,\n                \"fold\": fold_idx,\n                \"RMSE_mean_fold\": rmse_mean,\n                \"Pearson_fold\": float(pearson_v),\n                \"FID_fold\": float(fid_val),\n            }\n            with open(metrics_js, \"w\") as f:\n                json.dump(fold_metrics, f, indent=2)\n            print(f\"[cache] Saved fold-{fold_idx} metrics to {metrics_js}\")\n\n        # ---- accumulate / best tracking ----\n        rmse_folds.append(rmse_mean)\n        pearson_folds.append(pearson_v)\n        fid_folds.append(fid_val)\n\n        if best_rmse is None or rmse_mean < best_rmse:\n            best_rmse = rmse_mean\n            best_fold_idx = fold_idx\n            best_model_path = ckpt_path\n\n    if best_fold_idx is not None:\n        print(f\"[viz] Generating prediction visualizations for BEST fold {best_fold_idx}...\")\n        best_tag = f\"{data_name}_{title}_fold{best_fold_idx}\"\n        best_ckpt = os.path.join(cache_dir, f\"model_{best_tag}.pth\")\n        best_pre  = os.path.join(cache_dir, f\"preproc_{best_tag}.pkl\")\n        with open(splits_path, \"rb\") as f:\n            splits = pickle.load(f)\n        _, val_files_best = splits[best_fold_idx - 1]\n        with open(best_pre, \"rb\") as f:\n            reg_models, pca, pca_mean, pca_std, input_channels = pickle.load(f)\n        val_dataset_best = CustomDataset(\n            val_files_best, target_idx, control_markers_indices,\n            reg_models, pca, pca_mean, pca_std, input_channels,\n            n_components=n_components, cofactor=cofactor\n        )\n        model_best = ResNetUNet(in_channels=n_components).to(device)\n        state = torch.load(best_ckpt, map_location=device)\n        model_best.load_state_dict(state, strict=True)\n        \n        visualize_prediction(\n            model=model_best,\n            dataset=val_dataset_best,\n            device=device,\n            indices=None,\n            name=f\"{data_name}_{title}_fold{best_fold_idx}\"\n        )\n    \n    \n    print(f\"[res] Done training {title}!\")\n    print(f\"Stats: RMSE = {np.mean(rmse_folds):.3f} ± {np.std(rmse_folds):.3f} | \"\n          f\"Pearson = {np.mean(pearson_folds):.3f} ± {np.std(pearson_folds):.3f} | \"\n          f\"FID = {np.mean(fid_folds):.1f} ± {np.std(fid_folds):.1f}\")\n\n    results = {\n        \"marker\": title,\n        \"RMSE_mean\": float(np.mean(rmse_folds)),\n        \"RMSE_std\": float(np.std(rmse_folds)),\n        \"Pearson_mean\": float(np.mean(pearson_folds)),\n        \"Pearson_std\": float(np.std(pearson_folds)),\n        \"FID_mean(clean)\": float(np.mean(fid_folds)),\n        \"FID_std\": float(np.std(fid_folds)),\n        \"best_fold_idx\": int(best_fold_idx) if best_fold_idx is not None else None,\n    }\n    return results\n","metadata":{"trusted":true,"scrolled":true,"editable":false},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# load data","metadata":{"editable":false}},{"cell_type":"code","source":"dataset = \"jackson2020\"\npath = f\"/kaggle/input/{dataset}\"\ncontrol = [0, 33, 34] #histone_h3, dna1, dna2\n\nmarker_tasks = [\n    (\"histone_h3_trimethylate\", 1, control), #H3K27me3 \n    #('histone_h3_phospho', 14, control) #pHH3\n]\n\noptimize = True\n#best_hyperparams = {\n    #'lr': 3.2e-05,\n    #'alpha': 0.975}\n    \n#j_results = []\n\nfor idx, (title, target_idx, control_markers_indices) in enumerate(marker_tasks):\n    start_time = time.time()\n    print(f\"\\n{'='*10}\")\n    print(f\"Processing: {title} (Marker {idx+1}/{len(marker_tasks)})\")\n    print(f\"{'='*10}\\n\")\n    \n    # OPTIMIZE ON FIRST MARKER ONLY\n    if idx == 0 and optimize:\n        print(\"[info] Running hyperparameter optimization...\")\n        best_hyperparams = optimize_for_marker(\n            path, target_idx, control_markers_indices, title, dataset,\n            cache_dir=WORK_CACHE_ROOT\n        )\n        \n        print(f\"\\n [res] Best hyperparameters:\")\n        print(f\"   lr: {best_hyperparams['lr']:.2e}\")\n        print(f\"   alpha: {best_hyperparams['alpha']:.3f}\\n\")\n        \n        with open(f'{dataset}_best_hyperparams.json', 'w') as f:\n            json.dump(best_hyperparams, f, indent=2)\n    pass \n    print(f\"[info] Training {title}...\")\n    res = main(\n        path, target_idx, control_markers_indices,\n        title=title, data_name=dataset,\n        hyperparams=best_hyperparams \n    )\n    \n    df_res = pd.DataFrame([res])\n    df_res.to_csv(f\"{dataset}_results_{title}_optimized.csv\", index=False)\n    #j_results.append(res)\n    \n    elapsed = (time.time() - start_time) / 60\n    print(f\"[done] {title} complete in {elapsed:.1f} minutes\\n\")\n","metadata":{"trusted":true,"scrolled":true,"editable":false},"outputs":[],"execution_count":null}]}