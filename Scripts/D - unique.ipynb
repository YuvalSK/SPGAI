{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68e386a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4807a680354ee194687def1ba25fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import kagglehub\n",
    "kagglehub.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1355bbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data source import complete.\n"
     ]
    }
   ],
   "source": [
    "yuvalsamoilov_danenberg2022_path = kagglehub.dataset_download('yuvalsamoilov/danenberg2022')\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44f2adb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_msssim in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pytorch_msssim) (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_msssim) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pytorch_msssim) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pytorch_msssim) (3.0.3)\n",
      "Requirement already satisfied: imagecodecs in /usr/local/lib/python3.12/dist-packages (2025.11.11)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imagecodecs) (2.0.2)\n",
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.12/dist-packages (1.8.2)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (0.15.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
      "Requirement already satisfied: clean-fid in /usr/local/lib/python3.12/dist-packages (0.1.35)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clean-fid) (2.9.0+cu126)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clean-fid) (0.24.0+cu126)\n",
      "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.12/dist-packages (from clean-fid) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from clean-fid) (1.16.3)\n",
      "Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.12/dist-packages (from clean-fid) (4.67.1)\n",
      "Requirement already satisfied: pillow>=8.1 in /usr/local/lib/python3.12/dist-packages (from clean-fid) (11.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from clean-fid) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->clean-fid) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->clean-fid) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->clean-fid) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->clean-fid) (2025.11.12)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->clean-fid) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->clean-fid) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clean-fid) (3.0.3)\n",
      "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_msssim\n",
    "!pip install imagecodecs\n",
    "!pip install torchmetrics\n",
    "!pip install clean-fid\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa7c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tifffile\n",
    "import zipfile\n",
    "import imagecodecs\n",
    "import tempfile\n",
    "import pickle\n",
    "import json\n",
    "import imageio\n",
    "import sys\n",
    "import psutil\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import glob\n",
    "from collections import Counter, OrderedDict\n",
    "import cv2\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.parametrizations import weight_norm\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import models\n",
    "import skimage.transform\n",
    "from pytorch_msssim import ms_ssim\n",
    "from tqdm import tqdm\n",
    "import torchvision.utils as vutils\n",
    "from cleanfid import fid\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "#from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "params = {'axes.titlesize': 30,\n",
    "          'legend.fontsize': 16,\n",
    "          'figure.figsize': (16, 10),\n",
    "          'axes.labelsize': 16,\n",
    "          'axes.titlesize': 12,\n",
    "          'xtick.labelsize': 16,\n",
    "          'ytick.labelsize': 16,\n",
    "          'figure.titlesize': 30}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae079c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No previous cache found; starting fresh.\n"
     ]
    }
   ],
   "source": [
    "INPUT_CACHE_ROOT = \"/your-notebook-output-files/cv_cache\"\n",
    "WORK_CACHE_ROOT  = \"/cv_cache\"\n",
    "\n",
    "# restore previous cache if present\n",
    "if os.path.exists(INPUT_CACHE_ROOT):\n",
    "    os.makedirs(WORK_CACHE_ROOT, exist_ok=True)\n",
    "    for src in glob.glob(os.path.join(INPUT_CACHE_ROOT, \"**/*\"), recursive=True):\n",
    "        if os.path.isfile(src):\n",
    "            dst = src.replace(INPUT_CACHE_ROOT, WORK_CACHE_ROOT, 1)\n",
    "            os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "            shutil.copy2(src, dst)\n",
    "    print(f\"[init] Restored cache from {INPUT_CACHE_ROOT} -> {WORK_CACHE_ROOT}\")\n",
    "else:\n",
    "    os.makedirs(WORK_CACHE_ROOT, exist_ok=True)\n",
    "    print(\"No previous cache found; starting fresh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d521adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               total        used        free      shared  buff/cache   available\n",
      "Mem:            52Gi       1.3Gi        29Gi       1.0Mi        22Gi        51Gi\n",
      "Swap:             0B          0B          0B\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40725b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50Encoder(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = backbone.bn1\n",
    "        self.relu = backbone.relu\n",
    "        self.maxpool = backbone.maxpool\n",
    "        self.layer1 = backbone.layer1\n",
    "        self.layer2 = backbone.layer2\n",
    "        self.layer3 = backbone.layer3\n",
    "        self.layer4 = backbone.layer4\n",
    "        for param in backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for param in self.layer2.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in self.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        f0 = self.conv1(x)\n",
    "        f0 = self.bn1(f0)\n",
    "        f0 = self.relu(f0)\n",
    "        f0_pool = self.maxpool(f0)\n",
    "        f1 = self.layer1(f0_pool)\n",
    "        f2 = self.layer2(f1)\n",
    "        f3 = self.layer3(f2)\n",
    "        f4 = self.layer4(f3)\n",
    "        return f0, f1, f2, f3, f4\n",
    "\n",
    "\n",
    "class UNetDecoder(nn.Module):\n",
    "    def __init__(self, out_channels=1, p=0.2):\n",
    "        super().__init__()\n",
    "        # Stage f4(2048) -> f3 scale (target 1024 ch)\n",
    "        self.conv4_1 = nn.Sequential(\n",
    "            nn.Conv2d(2048 + 1024, 1024, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p),\n",
    "        )\n",
    "        self.conv4_2 = nn.Sequential(\n",
    "            nn.Conv2d(1024, 1024, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Stage -> f2 scale (target 512 ch)\n",
    "        self.conv3_1 = nn.Sequential(\n",
    "            nn.Conv2d(1024 + 512, 512, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p),\n",
    "        )\n",
    "        self.conv3_2 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Stage -> f1 scale (target 256 ch)\n",
    "        self.conv2_1 = nn.Sequential(\n",
    "            nn.Conv2d(512 + 256, 256, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p),\n",
    "        )\n",
    "        self.conv2_2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Stage -> combine (f1 + f0) at f1 scale (target 64 ch)\n",
    "        self.conv1_1 = nn.Sequential(\n",
    "            nn.Conv2d(256 + 256 + 64, 64, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout2d(p),\n",
    "        )\n",
    "        self.conv1_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        # Final upsample \n",
    "        self.final_up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "        # Light head\n",
    "        self.up0 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, 3, padding=1, padding_mode='reflect', bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.final = weight_norm(nn.Conv2d(32, out_channels, 1))\n",
    "\n",
    "    def forward(self, skips):\n",
    "        f0, f1, f2, f3, f4 = skips \n",
    "\n",
    "        # ---- up4: f4 -> f3 scale ----\n",
    "        x = F.interpolate(f4, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        if x.shape[-2:] != f3.shape[-2:]:\n",
    "            f3 = F.interpolate(f3, size=x.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, f3], dim=1)\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.conv4_2(x)\n",
    "\n",
    "        # ---- up3: -> f2 scale ----\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        if x.shape[-2:] != f2.shape[-2:]:\n",
    "            f2 = F.interpolate(f2, size=x.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, f2], dim=1)\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.conv3_2(x)\n",
    "\n",
    "        # ---- up2: -> f1 scale ----\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        if x.shape[-2:] != f1.shape[-2:]:\n",
    "            f1 = F.interpolate(f1, size=x.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, f1], dim=1)\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.conv2_2(x)\n",
    "\n",
    "        # ---- up1: combine f1 & f0 at f1 scale ----\n",
    "        # f0 may need resize to f1 scale\n",
    "        if f0.shape[-2:] != f1.shape[-2:]:\n",
    "            f0 = F.interpolate(f0, size=f1.shape[-2:], mode='bilinear', align_corners=False)\n",
    "        x = torch.cat([x, f1, f0], dim=1)\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.conv1_2(x)\n",
    "\n",
    "        # ---- final upsample + head ----\n",
    "        x = self.final_up(x) \n",
    "        x = self.up0(x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False) \n",
    "        x = torch.sigmoid(self.final(x))\n",
    "        return x\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super().__init__()\n",
    "        self.encoder = ResNet50Encoder(in_channels=in_channels)\n",
    "        self.decoder = UNetDecoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        skips = self.encoder(x)\n",
    "        return self.decoder(skips)\n",
    "\n",
    "# Wrap the lists in a custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_list, target_idx, control_markers_indices,\n",
    "                 regression_models, pca, pca_mean, pca_std, input_channels,\n",
    "                 n_components=3, cofactor=5.0, chunk_size=100_000):\n",
    "        self.file_list = file_list\n",
    "        self.target_idx = target_idx\n",
    "        self.control_markers_indices = control_markers_indices\n",
    "        self.regression_models = regression_models\n",
    "        self.pca = pca\n",
    "        self.pca_mean = pca_mean\n",
    "        self.pca_std = pca_std\n",
    "        self.input_channels = input_channels\n",
    "        self.n_components = n_components\n",
    "        self.cofactor = cofactor\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        x_tensor, y_tensor, _ = preprocess_image(\n",
    "            file_path,\n",
    "            self.target_idx,\n",
    "            self.control_markers_indices,\n",
    "            self.regression_models,\n",
    "            self.pca,\n",
    "            self.pca_mean,\n",
    "            self.pca_std,\n",
    "            self.input_channels,\n",
    "            self.n_components,\n",
    "            self.cofactor,\n",
    "            self.chunk_size\n",
    "        )\n",
    "        H, W = x_tensor.shape[1], x_tensor.shape[2]  \n",
    "        return x_tensor, y_tensor, (H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e9041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_hwc(img):\n",
    "    '''\n",
    "    Different libraries use different conventions.\n",
    "    - PyTorch: prefers CHW format (channels, height, width)\n",
    "    - TensorFlow/PIL/Matplotlib: prefer HWC format (height, width, channels)\n",
    "    The function ensures all images are consistently in HWC format for the preprocessing pipeline, regardless of how they were originally stored or loaded.\n",
    "    '''\n",
    "    if img.ndim == 2:\n",
    "        img = img[..., None]\n",
    "    if img.shape[0] < img.shape[1] and img.shape[0] < img.shape[2]:\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "    return img.astype(np.float32, copy=False)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def fit_preprocessing(\n",
    "    train_files,\n",
    "    target_idx,\n",
    "    control_markers_indices,\n",
    "    n_components=3,\n",
    "    batch_size=100_000,\n",
    "    cofactor=5.0,\n",
    "    eps=1e-8):\n",
    "    \"\"\"\n",
    "    Fit channel-wise regressions and incremental PCA on residuals from IMC training images with lazy loading.\n",
    "    Returns: (regression_models, pca, pca_mean, pca_std, input_channels)\n",
    "    \"\"\"\n",
    "\n",
    "    # Discover channel setup from the first image\n",
    "    input_channels = []\n",
    "    img0 = to_hwc(tifffile.imread(train_files[0]))\n",
    "    #print(f\"[info] example image shape: {img0.shape}\")\n",
    "    H, W, C = img0.shape\n",
    "    input_channels = [c for c in range(C) if c != target_idx and c not in control_markers_indices]\n",
    "    K = len(input_channels)\n",
    "    del img0; gc.collect()\n",
    "\n",
    "    if not input_channels:\n",
    "        print(f\"Warning: no inputs for target {target_idx} with controls {control_markers_indices}.\")\n",
    "        return None, None, None, None, input_channels\n",
    "\n",
    "    # 1. Fit regressions with SGDRegressor (partial_fit: true \"streaming\" mode)\n",
    "    regression_models = {}\n",
    "    first_pass = {}\n",
    "\n",
    "    for j in input_channels:\n",
    "        regression_models[j] = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "        first_pass[j] = True\n",
    "\n",
    "    for c, f in enumerate(train_files):\n",
    "        if c % int(len(train_files)/2) == 0 or c == len(train_files)-1:\n",
    "            print(f\"[prepro] extracting control and trg markers: {c+1} / {len(train_files)}\")\n",
    "        img = to_hwc(tifffile.imread(f))\n",
    "        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n",
    "        for j in input_channels:\n",
    "            y = img[..., j].reshape(-1)\n",
    "            if first_pass[j]:\n",
    "                regression_models[j].partial_fit(Xc, y)\n",
    "                first_pass[j] = False\n",
    "            else:\n",
    "                regression_models[j].partial_fit(Xc, y)\n",
    "        del img, Xc, y; gc.collect()\n",
    "\n",
    "    # 2. Incremental PCA on residuals (streamed, as before)\n",
    "    if n_components > K:\n",
    "        print(f\"n_components {n_components} > residual dim {K}; using {K}.\")\n",
    "        n_components = K\n",
    "    pca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "    for c, f in enumerate(train_files):\n",
    "        if c % int(len(train_files)/2) == 0 or c == len(train_files)-1:\n",
    "            print(f\"[prepro] fitting regression: {c+1} / {len(train_files)}\")\n",
    "\n",
    "        img = to_hwc(tifffile.imread(f))\n",
    "        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n",
    "        R = np.empty((Xc.shape[0], K), dtype=np.float32)\n",
    "        for k, j in enumerate(input_channels):\n",
    "            y = img[..., j].reshape(-1)\n",
    "            y_pred = regression_models[j].predict(Xc)\n",
    "            R[:, k] = y - y_pred.astype(np.float32, copy=False)\n",
    "        R = np.arcsinh(R / cofactor).astype(np.float32)\n",
    "        for s in range(0, R.shape[0], batch_size):\n",
    "            batch = R[s : s + batch_size]\n",
    "            pca.partial_fit(batch)\n",
    "        del img, Xc, R; gc.collect()\n",
    "\n",
    "    # 3. Compute mean/std of PCA space (streamed)\n",
    "    total = 0\n",
    "    sum_z = np.zeros(n_components, dtype=np.float64)\n",
    "    sumsq_z = np.zeros(n_components, dtype=np.float64)\n",
    "\n",
    "    for c, f in enumerate(train_files):\n",
    "        if c % int(len(train_files)/2) == 0 or c == len(train_files)-1:\n",
    "            print(f\"[prepro] normalization: {c+1} / {len(train_files)}\")\n",
    "\n",
    "        img = to_hwc(tifffile.imread(f))\n",
    "        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n",
    "        R = np.empty((Xc.shape[0], K), dtype=np.float32)\n",
    "        for k, j in enumerate(input_channels):\n",
    "            y = img[..., j].reshape(-1)\n",
    "            y_pred = regression_models[j].predict(Xc)\n",
    "            R[:, k] = y - y_pred.astype(np.float32, copy=False)\n",
    "        R = np.arcsinh(R / cofactor).astype(np.float32)\n",
    "        for s in range(0, R.shape[0], batch_size):\n",
    "            Z = pca.transform(R[s : s + batch_size]).astype(np.float32)\n",
    "            sum_z += Z.sum(axis=0)\n",
    "            sumsq_z += (Z * Z).sum(axis=0)\n",
    "            total += Z.shape[0]\n",
    "        del img, Xc, R, Z; gc.collect()\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"Warning: no residuals seen for PCA stats; using zeros/ones.\")\n",
    "        pca_mean = np.zeros(n_components, dtype=np.float32)\n",
    "        pca_std = np.ones(n_components, dtype=np.float32) * eps\n",
    "    else:\n",
    "        pca_mean = (sum_z / total).astype(np.float32)\n",
    "        var = (sumsq_z / total) - (pca_mean.astype(np.float64) ** 2)\n",
    "        pca_std = (np.sqrt(np.maximum(var, 0.0)) + eps).astype(np.float32)\n",
    "\n",
    "    # Print variance captured by PCs if possible\n",
    "    if hasattr(pca, \"explained_variance_ratio_\") and pca.explained_variance_ratio_ is not None:\n",
    "        pct = pca.explained_variance_ratio_[:n_components].sum() * 100.0\n",
    "        print(f\"[norm] PCA projection to {n_components}D captures {pct:.2f}% variance\")\n",
    "\n",
    "    return regression_models, pca, pca_mean, pca_std, input_channels\n",
    "\n",
    "def preprocess_image(\n",
    "    file_path,\n",
    "    target_idx,\n",
    "    control_markers_indices,\n",
    "    regression_models,\n",
    "    pca,\n",
    "    pca_mean,\n",
    "    pca_std,\n",
    "    input_channels,\n",
    "    n_components=3,\n",
    "    cofactor=5.0,\n",
    "    chunk_size=100_000):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single IMC image lazily by:\n",
    "    - loading image,\n",
    "    - normalizing target,\n",
    "    - computing residuals from regression,\n",
    "    - arcsinh transform,\n",
    "    - PCA transform in batches,\n",
    "    - Z-score normalization of PCA features,\n",
    "    - return PyTorch tensors for model input.\n",
    "    \"\"\"\n",
    "\n",
    "    img = tifffile.imread(file_path)\n",
    "    img = to_hwc(img)\n",
    "    H, W, C = img.shape\n",
    "    filename = os.path.basename(file_path)\n",
    "\n",
    "    # Normalize target channel intensities with arcsinh and min-max\n",
    "    target_data = img[..., target_idx]\n",
    "    y_arc = np.arcsinh(target_data / cofactor).astype(np.float32)\n",
    "    y_min, y_max = y_arc.min(), y_arc.max()\n",
    "    y_norm = (y_arc - y_min) / (y_max - y_min + 1e-8)\n",
    "    y_tensor = torch.from_numpy(y_norm[None, ...]).float()  # (1, H, W)\n",
    "\n",
    "    # Prepare control channel matrix\n",
    "    n_ctrl = len(control_markers_indices)\n",
    "    K = len(input_channels)\n",
    "    Xc = img[..., control_markers_indices].reshape(-1, n_ctrl)           # (N, n_ctrl)\n",
    "    Yin = np.stack([img[..., j].reshape(-1) for j in input_channels], 1)  # (N, K)\n",
    "\n",
    "    # Stack regression coef and intercept for vectorized prediction\n",
    "    B = np.stack([regression_models[j].coef_ for j in input_channels], axis=-1).astype(np.float32)  # (n_ctrl, K)\n",
    "    b = np.array([regression_models[j].intercept_ for j in input_channels], dtype=np.float32)       # (K,)\n",
    "    b = b.flatten()\n",
    "\n",
    "    # Predict residuals Y - regression(X)\n",
    "    Yhat = Xc @ B + b                                                # (N, K)\n",
    "    R = Yin - Yhat\n",
    "    R = np.arcsinh(R / cofactor).astype(np.float32)\n",
    "\n",
    "    # PCA transform in chunks, for low memory\n",
    "    N = R.shape[0]\n",
    "    Z = np.empty((N, n_components), dtype=np.float32)\n",
    "    for s in range(0, N, chunk_size):\n",
    "        e = s + chunk_size\n",
    "        Z[s:e] = pca.transform(R[s:e])\n",
    "\n",
    "    # Z-score normalize PCA components\n",
    "    Z = (Z - pca_mean) / (pca_std + 1e-8)\n",
    "    Z = Z.reshape(H, W, n_components)\n",
    "\n",
    "    # Convert PCA tensor to channel-first for PyTorch\n",
    "    x_tensor = torch.from_numpy(Z).permute(2, 0, 1).contiguous().float()  # (C, H, W)\n",
    "\n",
    "    return x_tensor, y_tensor, filename\n",
    "\n",
    "def apply_preprocessing(\n",
    "    files,\n",
    "    target_idx,\n",
    "    control_markers_indices,\n",
    "    regression_models,\n",
    "    pca,\n",
    "    pca_mean,\n",
    "    pca_std,\n",
    "    input_channels,\n",
    "    n_components=3,\n",
    "    cofactor=5.0,\n",
    "    chunk_size=100_000):\n",
    "    \n",
    "    X_pca_tensor, Y_norm_list, filenames = [], [], []\n",
    "\n",
    "    for c, f in enumerate(files):\n",
    "        if c % int(len(files)/2) == 0 or c == len(files)-1:\n",
    "            print(f\"[norm] applying preprocessing: {c+1} / {len(files)}\")\n",
    "\n",
    "        x_tensor, y_tensor, filename = preprocess_image(\n",
    "            f, target_idx, control_markers_indices, regression_models, pca,\n",
    "            pca_mean, pca_std, input_channels, n_components, cofactor, chunk_size\n",
    "        )\n",
    "        X_pca_tensor.append(x_tensor)\n",
    "        Y_norm_list.append(y_tensor)\n",
    "        filenames.append(filename)\n",
    "    return X_pca_tensor, Y_norm_list, filenames\n",
    "\n",
    "def pad_collate(batch):\n",
    "    \"\"\"\n",
    "    Pads all tensors in a batch to the largest size.\n",
    "    Also returns original sizes for cropping.\n",
    "    \"\"\"\n",
    "    X_list, Y_list, original_sizes = zip(*batch)\n",
    "\n",
    "    max_H = max([x.shape[1] for x in X_list])\n",
    "    max_W = max([x.shape[2] for x in X_list])\n",
    "\n",
    "    padded_X_list = []\n",
    "    padded_Y_list = []\n",
    "\n",
    "    for x_tensor, y_tensor in zip(X_list, Y_list):\n",
    "        pad_H = max_H - x_tensor.shape[1]\n",
    "        pad_W = max_W - x_tensor.shape[2]\n",
    "\n",
    "        padded_X = F.pad(x_tensor, (0, pad_W, 0, pad_H))\n",
    "        padded_Y = F.pad(y_tensor, (0, pad_W, 0, pad_H))\n",
    "\n",
    "        padded_X_list.append(padded_X)\n",
    "        padded_Y_list.append(padded_Y)\n",
    "\n",
    "\n",
    "    return torch.stack(padded_X_list), torch.stack(padded_Y_list), original_sizes\n",
    "\n",
    "def train_model(model, train_loader, val_loader, device, title,\n",
    "                config,\n",
    "                epochs=50,\n",
    "                huber_beta=1.0,\n",
    "                grad_clip=1.0,\n",
    "                use_amp=True,\n",
    "                patience=15,\n",
    "                save_path=\"best_model.pth\",\n",
    "                dataset=None,\n",
    "                ):\n",
    "\n",
    "    \"\"\"\n",
    "    Loss = alpha * Huber(y_hat, y) + (1 - alpha) * (1 - SSIM(y_hat_norm, y_norm)).\n",
    "    - Huber is on intensities.\n",
    "    - SSIM is per-image min-max normalized to [0,1].\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    lr = config.get('lr')\n",
    "    alpha = config.get('alpha')\n",
    "    opt = torch.optim.Adam(model.parameters(), lr = lr, weight_decay=1e-5)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=3)\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    best_val, best_state, best_epoch = float(\"inf\"), None, None\n",
    "    no_improve = 0\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Training loop unchanged\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for x, y, original_sizes in train_loader:\n",
    "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            B, _, H_padded, W_padded = x.shape  # Padded dimensions\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast(device_type='cuda', enabled=use_amp):\n",
    "                yhat = model(x)\n",
    "\n",
    "                hub_sum = 0.0\n",
    "                ssim_sum = 0.0\n",
    "                skip_batch = False\n",
    "\n",
    "                for i in range(B):\n",
    "                    h, w = original_sizes[i]\n",
    "                    y_i = y[i:i+1, :, :h, :w]  # Ground truth (cropped)\n",
    "                    yhat_i = yhat[i:i+1, :, :h, :w]  # Prediction (cropped)\n",
    "        \n",
    "                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n",
    "                    hub_sum += hub_i\n",
    "\n",
    "                    y_min, y_max = y_i.min().detach(), y_i.max().detach()\n",
    "                    yh_min, yh_max = yhat_i.min().detach(), yhat_i.max().detach()\n",
    "                    y_n = (y_i - y_min) / (y_max - y_min + epsilon)\n",
    "                    yhat_n = (yhat_i - yh_min) / (yh_max - yh_min + epsilon)\n",
    "                    \n",
    "                    ssim_sum += (1.0 - ms_ssim(yhat_n, y_n, data_range=1.0, win_size=7, weights=[0.4, 0.3, 0.3]))\n",
    "\n",
    "                hub_mean = hub_sum / B\n",
    "                ssim_mean = ssim_sum / B\n",
    "                \n",
    "                hub_mean = torch.as_tensor(hub_mean, device=device)\n",
    "                ssim_mean = torch.as_tensor(ssim_mean, device=device)\n",
    "\n",
    "                loss = alpha * hub_mean + (1 - alpha) * ssim_mean\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                if grad_clip is not None:\n",
    "                    scaler.unscale_(opt)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "\n",
    "                running += loss.item() * B\n",
    "\n",
    "        train_loss = running / len(train_loader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation loop with robust error checking and batch skipping\n",
    "        model.eval()\n",
    "        val_running = 0.0\n",
    "        valid_batches = 0\n",
    "        with torch.no_grad(), autocast(device_type='cuda', enabled=use_amp):\n",
    "            for batch_idx, (x, y, original_sizes) in enumerate(val_loader):\n",
    "                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "                B, _, H_padded, W_padded = x.shape  # Padded dimensions\n",
    "\n",
    "                yhat = model(x)\n",
    "\n",
    "                hub_sum = 0.0\n",
    "                ssim_sum = 0.0\n",
    "                skip_batch = False\n",
    "\n",
    "                for i in range(B):\n",
    "                    h, w = original_sizes[i]\n",
    "                    y_i = y[i:i+1, :, :h, :w]\n",
    "                    yhat_i = yhat[i:i+1, :, :h, :w]\n",
    "\n",
    "                    # Clamp predictions between 0 and 1 for numerical stability\n",
    "                    yhat_i = torch.clamp(yhat_i, min=0.0, max=1.0)\n",
    "                        \n",
    "                    y_min, y_max = y_i.min(), y_i.max()\n",
    "                    yh_min, yh_max = yhat_i.min(), yhat_i.max()\n",
    "                    denom_y = (y_max - y_min).abs() + epsilon\n",
    "                    denom_yh = (yh_max - yh_min).abs() + epsilon\n",
    "\n",
    "                    if denom_y < epsilon or denom_yh < epsilon:\n",
    "                        #print(f\"Note: validation batch {batch_idx}, sample {i} skipped due to near-constant values\")\n",
    "                        skip_batch = True\n",
    "                        break\n",
    "\n",
    "                    y_n = (y_i - y_min) / denom_y\n",
    "                    yhat_n = (yhat_i - yh_min) / denom_yh\n",
    "\n",
    "                    ssim_val = ms_ssim(yhat_n, y_n, data_range=1.0, win_size=7, weights=[0.4, 0.3, 0.3])\n",
    "                    if torch.isnan(ssim_val) or torch.isinf(ssim_val):\n",
    "                        #print(f\"Note: validation batch {batch_idx}, sample {i} SSIM returned NaN or Inf, skipping batch\")\n",
    "                        skip_batch = True\n",
    "                        break\n",
    "\n",
    "                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n",
    "                    if torch.isnan(hub_i) or torch.isinf(hub_i):\n",
    "                        #print(f\"Note: validation batch {batch_idx}, sample {i} Huber loss returned NaN or Inf, skipping batch\")\n",
    "                        skip_batch = True\n",
    "                        break\n",
    "\n",
    "                    hub_sum += hub_i\n",
    "                    ssim_sum += (1.0 - ssim_val)\n",
    "\n",
    "                if skip_batch:\n",
    "                    continue  # Skip entire batch aggregation\n",
    "\n",
    "                val_loss_batch = (alpha * hub_sum + (1 - alpha) * ssim_sum) / B\n",
    "                if torch.isnan(val_loss_batch) or torch.isinf(val_loss_batch):\n",
    "                    #print(f\"Note: validation batch {batch_idx} computed val_loss_batch as NaN or Inf, skipping\")\n",
    "                    continue\n",
    "\n",
    "                val_running += float(val_loss_batch) * B\n",
    "                valid_batches += B\n",
    "\n",
    "        if valid_batches > 0:\n",
    "            val_loss = val_running / valid_batches\n",
    "        else:\n",
    "            val_loss = float('nan')\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        sched.step(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:>3d} | Train {train_loss:.3f} | Val {val_loss:.3f}\")\n",
    "\n",
    "        # ---- Early stopping ----\n",
    "        if val_loss + 1e-6 < best_val:\n",
    "            best_val, best_epoch = val_loss, epoch + 1\n",
    "            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "            no_improve = 0\n",
    "            print(f\"  ↳ New best val={val_loss:.3f} at epoch {best_epoch}\")\n",
    "            if save_path:\n",
    "                torch.save(best_state, save_path)\n",
    "                print(f\"  ↳ Saved checkpoint to {save_path}\")\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            print(f\"  ↳ No improvement ({no_improve}/{patience} patience)\")\n",
    "            current_lr = opt.param_groups[0][\"lr\"]\n",
    "            print(f\"  ↳ LR: {current_lr:.2e}\")\n",
    "            if patience is not None and no_improve >= patience:\n",
    "                print(f\"--Early stopping at epoch {epoch+1}. Best epoch was {best_epoch} with val={best_val:.3f}\")\n",
    "                break\n",
    "\n",
    "    # Restore best weights\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "        print(f\"--Restored model weights from epoch {best_epoch} (val={best_val:.3f})\")\n",
    "\n",
    "    # Plot losses\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, len(train_losses)+1), train_losses, marker='o', label='Train')\n",
    "    plt.plot(range(1, len(val_losses)+1), val_losses, marker='s', label='Val')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'Marker: {title}')\n",
    "    plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    return train_losses, val_losses\n",
    "    \n",
    "def visualize_prediction(model, dataset, device, indices=None, target_channel=0, name=\"comparison_grid\"):\n",
    "    \"\"\"\n",
    "    Show & save some example pairs (GT | Pred). \n",
    "    \"\"\"\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    eps = 1e-8  # small constant to avoid division by zero\n",
    "\n",
    "    if indices is None:\n",
    "        k = 25\n",
    "        # sample without replacement; if len<5 just take range(k)\n",
    "        indices = random.sample(range(len(dataset)), k) if len(dataset) >= k else list(range(len(dataset)))\n",
    "\n",
    "    # build figure\n",
    "    n = len(indices)\n",
    "    fig, axs = plt.subplots(n, 2, figsize=(8, 4 * n))\n",
    "    if n == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)  # make it 2D\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for row, idx in enumerate(indices):\n",
    "            x_tensor, y_tensor, _ = dataset[idx]\n",
    "            x_tensor = x_tensor.unsqueeze(0).to(device)\n",
    "            y_tensor = y_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "            y_pred = model(x_tensor)\n",
    "\n",
    "            # crop out tile borders to remove padding artifacts\n",
    "            crop_margin = 64  # try 32 or 64 depending on your tile size\n",
    "            _, _, H, W = y_pred.shape\n",
    "            y_pred = y_pred[:, :, crop_margin:H - crop_margin, crop_margin:W - crop_margin]\n",
    "            \n",
    "            # also crop ground truth to match\n",
    "            y_tensor = y_tensor[:, :, crop_margin:H - crop_margin, crop_margin:W - crop_margin]\n",
    "            \n",
    "            \n",
    "            # to numpy, select channel, [0,1] normalize\n",
    "            y_true_np = y_tensor.squeeze().detach().cpu().numpy()\n",
    "            y_pred_np = y_pred.squeeze().detach().cpu().numpy()\n",
    "            if y_true_np.ndim == 3:\n",
    "                y_true_np = y_true_np[target_channel]\n",
    "            if y_pred_np.ndim == 3:\n",
    "                y_pred_np = y_pred_np[target_channel]\n",
    "            \n",
    "            # ----- visualization-only rescaling -----\n",
    "            # Limitation: \n",
    "            # This visualization only rescales the predictions to look more like the ground truth \n",
    "            # it does not fix or reflect the true quantitative errors or background bias of the model (maybe add mask and replace ms_ssim with BCE).\n",
    "\n",
    "            gt = y_true_np.astype(np.float32)\n",
    "            pr = y_pred_np.astype(np.float32)\n",
    "            gt_mean, gt_std = gt.mean(), gt.std()\n",
    "            pr_mean, pr_std = pr.mean(), pr.std()\n",
    "            pr_adj = (pr - pr_mean) / pr_std * gt_std + gt_mean\n",
    "            stack = np.concatenate([gt.flatten(), pr_adj.flatten()])\n",
    "            s_min, s_max = stack.min(), stack.max()\n",
    "            s_range = s_max - s_min + eps\n",
    "            \n",
    "            y_true_vis = (gt - s_min) / s_range\n",
    "            y_pred_vis = (pr_adj - s_min) / s_range\n",
    "\n",
    "            #edits#\n",
    "            vmin = y_true_np.min()\n",
    "            vmax = y_true_np.max()\n",
    "            #end#\n",
    "\n",
    "            axs[row, 0].imshow(y_true_vis, cmap=\"inferno\", vmin=vmin, vmax=vmax)\n",
    "            axs[row, 0].set_title(f\"Ground Truth (idx {idx})\")\n",
    "            axs[row, 0].axis(\"off\")\n",
    "\n",
    "            axs[row, 1].imshow(y_pred_vis, cmap=\"inferno\", vmin=vmin, vmax=vmax)\n",
    "            axs[row, 1].set_title(\"Prediction\")\n",
    "            axs[row, 1].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(f\"{name}\", fontsize=14)\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "\n",
    "    # always save (headless-friendly), then show if a display exists\n",
    "    out_path = f\"comparison_grid_{name}.png\"\n",
    "    fig.savefig(out_path, dpi=400, bbox_inches=\"tight\")\n",
    "    plt.show() \n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"[vis] Saved comparison figure to: {out_path}\")\n",
    "\n",
    "def smart_load_state_dict(model, state, strict=True):\n",
    "    \n",
    "    is_dp = isinstance(model, torch.nn.DataParallel)\n",
    "    has_module = all(k.startswith(\"module.\") for k in state.keys())\n",
    "    if is_dp and not has_module:\n",
    "        return model.module.load_state_dict(state, strict=strict)          \n",
    "    if (not is_dp) and has_module:\n",
    "        state = {k.replace(\"module.\", \"\", 1): v for k, v in state.items()}  \n",
    "        return model.load_state_dict(state, strict=strict)\n",
    "    target = model.module if is_dp else model\n",
    "    return target.load_state_dict(state, strict=strict)\n",
    "\n",
    "def train_model_with_config(\n",
    "    model, train_loader, val_loader, device, title,\n",
    "    config: dict,\n",
    "    save_path=\"best_model.pth\"):\n",
    "    \"\"\"\n",
    "    Modified training function that accepts a config dictionary.\n",
    "    Returns best validation loss for optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    # Extract hyperparameters from config\n",
    "    lr = config.get('lr', 1e-4)\n",
    "    alpha = config.get('alpha', 0.8)\n",
    "    huber_beta = config.get('huber_beta', 1.0)\n",
    "    weight_decay = config.get('weight_decay', 1e-5)\n",
    "    grad_clip = config.get('grad_clip', 1.0)\n",
    "    scheduler_patience = config.get('scheduler_patience', 3)\n",
    "    scheduler_factor = config.get('scheduler_factor', 0.5)\n",
    "    epochs = config.get('epochs', 50)\n",
    "    early_stop_patience = config.get('early_stop_patience', 10)\n",
    "\n",
    "    # Setup optimizer and scheduler\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        opt, mode=\"min\", factor=scheduler_factor, patience=scheduler_patience\n",
    "    )\n",
    "    scaler = GradScaler(enabled=True)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    no_improve = 0\n",
    "    epsilon = 1e-8\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "        for x, y, original_sizes in train_loader:\n",
    "            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "            B = x.shape[0]\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast(device_type='cuda', enabled=True):\n",
    "                yhat = model(x)\n",
    "\n",
    "                hub_sum = 0.0\n",
    "                ssim_sum = 0.0\n",
    "                for i in range(B):\n",
    "                    h, w = original_sizes[i]\n",
    "                    y_i = y[i:i+1, :, :h, :w]\n",
    "                    yhat_i = yhat[i:i+1, :, :h, :w]\n",
    "\n",
    "                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n",
    "                    hub_sum += hub_i\n",
    "\n",
    "                    y_min, y_max = y_i.min().detach(), y_i.max().detach()\n",
    "                    yh_min, yh_max = yhat_i.min().detach(), yhat_i.max().detach()\n",
    "                    y_n = (y_i - y_min) / (y_max - y_min + epsilon)\n",
    "                    yhat_n = (yhat_i - yh_min) / (yh_max - yh_min + epsilon)\n",
    "                    \n",
    "                    ssim_sum += (1.0 - ms_ssim(yhat_n, y_n, data_range=1.0, win_size=7, weights=[0.4, 0.3, 0.3]))\n",
    "\n",
    "                hub_mean = hub_sum / B\n",
    "                ssim_mean = ssim_sum / B\n",
    "\n",
    "                hub_mean = torch.as_tensor(hub_mean, device=device)\n",
    "                ssim_mean = torch.as_tensor(ssim_mean, device=device)\n",
    "\n",
    "                loss = alpha * hub_mean + (1 - alpha) * ssim_mean\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            if grad_clip is not None:\n",
    "                scaler.unscale_(opt)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            running += loss.item() * B\n",
    "\n",
    "        train_loss = running / len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_running = 0.0\n",
    "        valid_batches = 0\n",
    "        \n",
    "        with torch.no_grad(), autocast(device_type='cuda', enabled=True):\n",
    "            for x, y, original_sizes in val_loader:\n",
    "                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "                B = x.shape[0]\n",
    "                yhat = model(x)\n",
    "\n",
    "                hub_sum = 0.0\n",
    "                ssim_sum = 0.0\n",
    "                skip_batch = False\n",
    "\n",
    "                for i in range(B):\n",
    "                    h, w = original_sizes[i]\n",
    "                    y_i = y[i:i+1, :, :h, :w]\n",
    "                    yhat_i = yhat[i:i+1, :, :h, :w]\n",
    "                    yhat_i = torch.clamp(yhat_i, min=0.0, max=1.0)\n",
    "\n",
    "                    y_min, y_max = y_i.min(), y_i.max()\n",
    "                    yh_min, yh_max = yhat_i.min(), yhat_i.max()\n",
    "                    \n",
    "                    y_n = (y_i - y_min) / ((y_max - y_min).abs() + epsilon)\n",
    "                    yhat_n = (yhat_i - yh_min) / ((yh_max - yh_min).abs() + epsilon)\n",
    "\n",
    "                    ssim_val = ms_ssim(yhat_n, y_n, data_range=1.0, weights=[0.4, 0.3, 0.3])\n",
    "                                        # Check for NaN/Inf\n",
    "                    if torch.isnan(ssim_val) or torch.isinf(ssim_val):\n",
    "                        skip_batch = True\n",
    "                        break\n",
    "                    \n",
    "                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n",
    "\n",
    "                    if torch.isnan(hub_i) or torch.isinf(hub_i):\n",
    "                        skip_batch = True\n",
    "                        break\n",
    "                        \n",
    "                    hub_sum += hub_i\n",
    "                    ssim_sum += (1.0 - ssim_val)\n",
    "\n",
    "                if not skip_batch:\n",
    "                    val_loss_batch = (alpha * hub_sum + (1 - alpha) * ssim_sum) / B\n",
    "                    if not (torch.isnan(val_loss_batch) or torch.isinf(val_loss_batch)):\n",
    "                        val_running += float(val_loss_batch) * B\n",
    "                        valid_batches += B\n",
    "\n",
    "        val_loss = val_running / valid_batches if valid_batches > 0 else float('nan')\n",
    "        sched.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss + 1e-6 < best_val:\n",
    "            best_val = val_loss\n",
    "            no_improve = 0\n",
    "            if save_path:\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= early_stop_patience:\n",
    "                print(f\"Early stop at epoch {epoch+1}, best val={best_val:.4f}\")\n",
    "                break\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f}\")\n",
    "\n",
    "    return best_val\n",
    "\n",
    "def objective(trial: Trial, train_loader, val_loader, device, model_fn, title):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter search.\n",
    "\n",
    "    Args:\n",
    "        trial: Optuna trial object\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        device: PyTorch device\n",
    "        model_fn: Function that returns a fresh model instance\n",
    "        title: Experiment title\n",
    "\n",
    "    Returns:\n",
    "        best_val_loss: Best validation loss achieved\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample hyperparameters\n",
    "    config = {\n",
    "        'lr': trial.suggest_float('lr', 3e-6, 5e-4, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 0.9, 0.99),\n",
    "        'epochs': 5, \n",
    "\n",
    "    }\n",
    "\n",
    "    # Create fresh model\n",
    "    model = model_fn()\n",
    "\n",
    "    # Train and get best validation loss\n",
    "    try:\n",
    "        best_val = train_model_with_config(\n",
    "            model, train_loader, val_loader, device, title,\n",
    "            config=config,\n",
    "            save_path=f\"trial_{trial.number}_best.pth\"\n",
    "        )\n",
    "        return best_val\n",
    "    except Exception as e:\n",
    "        print(f\"Trial {trial.number} failed: {e}\")\n",
    "        return float('inf')\n",
    "\n",
    "def run_hyperparameter_search(\n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    device, \n",
    "    model_fn,\n",
    "    title,\n",
    "    n_trials=6,\n",
    "    study_name=\"stain_translation_opt\"):\n",
    "    \"\"\"\n",
    "    Run Optuna hyperparameter optimization.\n",
    "\n",
    "    Args:\n",
    "        train_loader: Training data loader\n",
    "        val_loader: Validation data loader\n",
    "        device: PyTorch device\n",
    "        model_fn: Function that returns a fresh model instance (e.g., lambda: ResNet50UNet(...))\n",
    "        title: Experiment title\n",
    "        n_trials: Number of optimization trials\n",
    "        study_name: Name for the Optuna study\n",
    "\n",
    "    Returns:\n",
    "        study: Optuna study object with results\n",
    "    \"\"\"\n",
    "\n",
    "    # Create study\n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        study_name=study_name,\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, train_loader, val_loader, device, model_fn, title),\n",
    "        n_trials=n_trials,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*10)\n",
    "    print(\"HYPERPARAMETER OPTIMIZATION RESULTS\")\n",
    "    print(\"=\"*10)\n",
    "    print(f\"Best trial: {study.best_trial.number}\")\n",
    "    print(f\"Best validation loss: {study.best_value:.6f}\")\n",
    "    print(f\"\\nBest hyperparameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    # Plot optimization history\n",
    "    fig = optuna.visualization.plot_optimization_history(study)\n",
    "    fig.show()\n",
    "\n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    fig.show()\n",
    "\n",
    "    return study\n",
    "\n",
    "def optimize_for_marker(path, target_idx, control_markers_indices, title, \n",
    "                        data_name, sample_fraction=0.2): \n",
    "    \"\"\"Run optimization on fold 1, return best hyperparameters.\"\"\"\n",
    "    \n",
    "    n_components = 3\n",
    "    cofactor = 5.0\n",
    "    batch_size = 2\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    all_files = sorted([os.path.join(path, f) for f in os.listdir(path) \n",
    "                       if f.endswith(('.tif', '.tiff'))])\n",
    "    \n",
    "    random.shuffle(all_files)\n",
    "    split_idx = int(0.75 * len(all_files))\n",
    "    train_files = all_files[:split_idx]\n",
    "    val_files = all_files[split_idx:]\n",
    "    \n",
    "    print(f\"[split] {len(train_files)} train, {len(val_files)} val\")\n",
    "\n",
    "    # Fit preprocessing\n",
    "    print(f\"[fitting] Running preprocessing...\")\n",
    "    regression_models, pca, pca_mean, pca_std, input_channels = fit_preprocessing(\n",
    "        train_files, target_idx, control_markers_indices, \n",
    "        n_components=n_components, cofactor=cofactor\n",
    "    )\n",
    "    \n",
    "    # Subsample training data (for speed)\n",
    "    n_train_samples = max(50, int(len(train_files) * sample_fraction))\n",
    "    train_files_subset = random.sample(train_files, n_train_samples)\n",
    "    \n",
    "    print(f\"[info] Using {len(train_files_subset)} train samples (20%)\")\n",
    "    print(f\"[info] Using {len(val_files)} val samples (100%)\")\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train, Y_train, _ = apply_preprocessing(\n",
    "        train_files_subset,  \n",
    "        target_idx, control_markers_indices,\n",
    "        regression_models, pca, pca_mean, pca_std, input_channels,\n",
    "        n_components=n_components, cofactor=cofactor\n",
    "    )\n",
    "    \n",
    "    X_val, Y_val, _ = apply_preprocessing(\n",
    "        val_files,\n",
    "        target_idx, control_markers_indices,\n",
    "        regression_models, pca, pca_mean, pca_std, input_channels,\n",
    "        n_components=n_components, cofactor=cofactor\n",
    "    )\n",
    "    \n",
    "    train_dataset = list(zip(X_train, Y_train, [x.shape[1:] for x in X_train]))\n",
    "    val_dataset = list(zip(X_val, Y_val, [x.shape[1:] for x in X_val]))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                             shuffle=True, collate_fn=pad_collate)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, \n",
    "                           shuffle=False, collate_fn=pad_collate)\n",
    "    \n",
    "    # Optimization\n",
    "    def create_model():\n",
    "        return ResNetUNet(in_channels=n_components)\n",
    "    \n",
    "    study = run_hyperparameter_search(\n",
    "        train_loader, val_loader, device, create_model,\n",
    "        title=title, n_trials=6, study_name=f\"{data_name}_{title}_opt\"\n",
    "    )\n",
    "    \n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36508732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(\n",
    "    path: str,\n",
    "    target_idx: int,\n",
    "    control_markers_indices: list,\n",
    "    title: str = \"Unspecified\",\n",
    "    n_splits: int = 3,\n",
    "    batch_size: int = 2,\n",
    "    device: str = None,\n",
    "    data_name: str = None,\n",
    "    cache_dir: str = \"./cv_cache\",\n",
    "    resume: bool = True,\n",
    "    n_components: int = 3,\n",
    "    cofactor: float = 5.0,\n",
    "    n_trials: int = 10,\n",
    "    finetune = False\n",
    "):\n",
    "    '''\n",
    "    Complete workflow:\n",
    "    1. Split data into train (80%) and test (20%)\n",
    "    2. Run hyperparameter optimization with k-fold CV on train set only\n",
    "    3. Train final model on full train set with best hyperparameters\n",
    "    4. Evaluate on held-out test set\n",
    "    '''\n",
    "\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    set_seed(42)\n",
    "\n",
    "    best_hyperparams = {'lr': 1e-3,\n",
    "                        'alpha': 0.90}\n",
    "    \n",
    "        \n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    all_files = sorted([\n",
    "        os.path.join(path, f) for f in os.listdir(path) \n",
    "        if f.endswith(('.tif', '.tiff'))\n",
    "    ])\n",
    "\n",
    "    split_path = os.path.join(cache_dir, f\"train_test_split_{data_name}_{title}.pkl\")\n",
    "    if resume and os.path.exists(split_path):\n",
    "        with open(split_path, \"rb\") as f:\n",
    "            train_files, test_files = pickle.load(f)\n",
    "        print(f\"[init] Loaded train/test split from {split_path}\")\n",
    "    else:\n",
    "        random.shuffle(all_files)\n",
    "        split_idx = int(0.75 * len(all_files))\n",
    "        train_files = all_files[:split_idx]\n",
    "        test_files = all_files[split_idx:]\n",
    "        with open(split_path, \"wb\") as f:\n",
    "            pickle.dump((train_files, test_files), f)\n",
    "        print(f\"[init] Created train/test split: {len(train_files)} train, {len(test_files)} test\")\n",
    "\n",
    "    print(f\"[split] Train: {len(train_files)}, Test: {len(test_files)}\")\n",
    "\n",
    "    # STEP 2: Hyperparameter Optimization with CV on Train Set\n",
    "    #print(f\"\\n{'='*10}\")\n",
    "    #print(f\"STEP 2: HYPERPARAMETER OPTIMIZATION\")\n",
    "    #print(f\"{'='*10}\")\n",
    "    \n",
    "    \n",
    "    if finetune == True:\n",
    "        cv_files = random.sample(train_files, len(train_files)//3) #third of train for cv and hyperparams finetuning \n",
    "\n",
    "        best_hyperparams = run_cv_optimization(\n",
    "            train_files=cv_files,\n",
    "            target_idx=target_idx,\n",
    "            control_markers_indices=control_markers_indices,\n",
    "            title=title,\n",
    "            data_name=data_name,\n",
    "            n_splits=n_splits,\n",
    "            batch_size=batch_size,\n",
    "            device=device,\n",
    "            cache_dir=cache_dir,\n",
    "            n_components=n_components,\n",
    "            cofactor=cofactor,\n",
    "            n_trials=n_trials,\n",
    "            resume=resume\n",
    "        )\n",
    "\n",
    "        #print(f\"\\n[result] Best hyperparameters found:\")\n",
    "        #print(f\"  lr: {best_hyperparams['lr']:.4f}\")\n",
    "        #print(f\"  alpha: {best_hyperparams['alpha']:.4f}\")\n",
    "\n",
    "        # Save best hyperparameters\n",
    "        hyperparam_path = os.path.join(cache_dir, f\"best_hyperparams_{data_name}_{title}.json\")\n",
    "        with open(hyperparam_path, \"w\") as f:\n",
    "            json.dump(best_hyperparams, f, indent=2)\n",
    "        print(f\"[cache] Saved best hyperparameters to {hyperparam_path}\")\n",
    "\n",
    "        print(f\"\\n{'='*10}\")\n",
    "        print(f\"STEP 3: TRAINING FINAL MODEL (full train set)\")\n",
    "        print(f\"{'='*10}\")\n",
    "\n",
    "    final_model_path = os.path.join(cache_dir, f\"final_model_{data_name}_{title}.pth\")\n",
    "    preproc_path = os.path.join(cache_dir, f\"final_preproc_{data_name}_{title}.pkl\")\n",
    "\n",
    "    # Fit preprocessing on full train set\n",
    "    if resume and os.path.exists(preproc_path):\n",
    "        with open(preproc_path, \"rb\") as f:\n",
    "            reg_models, pca, pca_mean, pca_std, input_channels = pickle.load(f)\n",
    "        print(f\"[init] Loaded preprocessing from {preproc_path}\")\n",
    "    else:\n",
    "        print(f\"[prepro] Fitting on {len(train_files)} training images...\")\n",
    "        reg_models, pca, pca_mean, pca_std, input_channels = fit_preprocessing(\n",
    "            train_files, target_idx, control_markers_indices,\n",
    "            n_components=n_components, cofactor=cofactor\n",
    "        )\n",
    "        with open(preproc_path, \"wb\") as f:\n",
    "            pickle.dump((reg_models, pca, pca_mean, pca_std, input_channels), f)\n",
    "        print(f\"[cache] Saved preprocessing to {preproc_path}\")\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = CustomDataset(\n",
    "        train_files, target_idx, control_markers_indices,\n",
    "        reg_models, pca, pca_mean, pca_std, input_channels,\n",
    "        n_components=n_components, cofactor=cofactor\n",
    "    )\n",
    "\n",
    "    test_dataset = CustomDataset(\n",
    "        test_files, target_idx, control_markers_indices,\n",
    "        reg_models, pca, pca_mean, pca_std, input_channels,\n",
    "        n_components=n_components, cofactor=cofactor\n",
    "    )\n",
    "\n",
    "    train_size = int(0.75 * len(train_dataset))\n",
    "    \n",
    "    val_size = len(train_dataset) - train_size\n",
    "\n",
    "    train_subset, val_subset = random_split(\n",
    "        train_dataset, [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_subset, batch_size=batch_size, shuffle=True,\n",
    "        collate_fn=pad_collate, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_subset, batch_size=batch_size, shuffle=False,\n",
    "        collate_fn=pad_collate, num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Train final model\n",
    "    model = ResNetUNet(in_channels=n_components).to(device)\n",
    "    \n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    if resume and os.path.exists(final_model_path):\n",
    "        print(f\"[init] Loading existing final model from {final_model_path}\")\n",
    "        state = torch.load(final_model_path, map_location=device)\n",
    "        smart_load_state_dict(model, state, strict=True)\n",
    "    else:\n",
    "        print(f\"[training] Training final model\")\n",
    "        train_model(\n",
    "            model, train_loader, val_loader, device,\n",
    "            config=best_hyperparams,\n",
    "            title=f\"{title} (final)\",\n",
    "            epochs=50,\n",
    "            patience=12,\n",
    "            save_path=final_model_path,\n",
    "            dataset=data_name\n",
    "        )\n",
    "        print(f\"[cache] Saved final model to {final_model_path}\")\n",
    "\n",
    "    print(f\"\\n{'='*10}\")\n",
    "    print(f\"FINAL EVALUATION\")\n",
    "    print(f\"{'='*10}\")\n",
    "\n",
    "    test_metrics = evaluate_model(\n",
    "        model=model,\n",
    "        dataset=test_dataset,\n",
    "        device=device,\n",
    "        batch_size=batch_size,\n",
    "        title=title,\n",
    "        data_name=data_name\n",
    "    )\n",
    "\n",
    "    print(f\"[FINAL RESULTS] {title}\")\n",
    "    print(f\"  Test RMSE: {test_metrics['rmse']:.4f}\")\n",
    "    print(f\"  Test Pearson: {test_metrics['pearson']:.4f}\")\n",
    "    print(f\"  Test FID: {test_metrics['fid']:.2f}\")\n",
    "    print(f\"  Hyperparams: {best_hyperparams}\")\n",
    "\n",
    "    visualize_prediction(\n",
    "        model=model,\n",
    "        dataset=test_dataset,\n",
    "        device=device,\n",
    "        indices=None,\n",
    "        target_channel=0,\n",
    "        name=title\n",
    "    )\n",
    "\n",
    "    # Save final metrics\n",
    "    metrics_path = os.path.join(cache_dir, f\"final_metrics_{data_name}_{title}.json\")\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(test_metrics, f, indent=2)\n",
    "    print(f\"[cache] Saved final metrics to {metrics_path}\")\n",
    "\n",
    "def run_cv_optimization(\n",
    "    train_files,\n",
    "    target_idx,\n",
    "    control_markers_indices,\n",
    "    title,\n",
    "    data_name,\n",
    "    n_splits=3,\n",
    "    batch_size=2,\n",
    "    device=\"cuda\",\n",
    "    cache_dir=\"./cv_cache\",\n",
    "    n_components=3,\n",
    "    cofactor=5.0,\n",
    "    n_trials=10,\n",
    "    resume=True\n",
    "):\n",
    "    '''\n",
    "    Run k-fold cross-validation with Optuna hyperparameter optimization.\n",
    "    Uses ONLY train_files - no test set contamination.\n",
    "\n",
    "    Returns:\n",
    "        best_hyperparams: dict with optimal 'lr' and 'alpha'\n",
    "    '''\n",
    "\n",
    "    # Create k-fold splits on train files ONLY\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cv_splits = []\n",
    "    for tr_idx, va_idx in kf.split(train_files):\n",
    "        tr_files = [train_files[i] for i in tr_idx]\n",
    "        va_files = [train_files[i] for i in va_idx]\n",
    "        cv_splits.append((tr_files, va_files))\n",
    "\n",
    "    print(f\"[cv] Created {n_splits}-fold CV splits on {len(train_files)} training files\")\n",
    "\n",
    "    # Define Optuna objective that uses CV\n",
    "    def objective(trial: Trial):\n",
    "        # Sample hyperparameters\n",
    "        lr = trial.suggest_float('lr', 3e-5, 5e-4, log=True)\n",
    "        alpha = trial.suggest_float('alpha', 0.9, 0.99)\n",
    "\n",
    "        fold_val_losses = []\n",
    "\n",
    "        # Evaluate this hyperparameter set across all CV folds\n",
    "        for fold_idx, (tr_files, va_files) in enumerate(cv_splits, 1):\n",
    "            print(f\"[Trial {trial.number}] Fold {fold_idx}/{n_splits} | lr={lr:.2e}, alpha={alpha:.3f}\")\n",
    "\n",
    "            # Fit preprocessing on this fold's training data\n",
    "            reg_models, pca, pca_mean, pca_std, input_channels = fit_preprocessing(\n",
    "                tr_files, target_idx, control_markers_indices,\n",
    "                n_components=n_components, cofactor=cofactor\n",
    "            )\n",
    "\n",
    "            # Create datasets\n",
    "            tr_dataset = CustomDataset(\n",
    "                tr_files, target_idx, control_markers_indices,\n",
    "                reg_models, pca, pca_mean, pca_std, input_channels,\n",
    "                n_components=n_components, cofactor=cofactor\n",
    "            )\n",
    "            va_dataset = CustomDataset(\n",
    "                va_files, target_idx, control_markers_indices,\n",
    "                reg_models, pca, pca_mean, pca_std, input_channels,\n",
    "                n_components=n_components, cofactor=cofactor\n",
    "            )\n",
    "\n",
    "            tr_loader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True, \n",
    "                                   collate_fn=pad_collate)\n",
    "            va_loader = DataLoader(va_dataset, batch_size=batch_size, shuffle=False,\n",
    "                                   collate_fn=pad_collate)\n",
    "\n",
    "            # Train model with these hyperparameters\n",
    "            model = ResNetUNet(in_channels=n_components).to(device)\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                model = torch.nn.DataParallel(model)\n",
    "\n",
    "            config = {'lr': lr, 'alpha': alpha, 'epochs': n_trials}  # Shorter for speed\n",
    "\n",
    "            try:\n",
    "                val_loss = train_model_with_config(\n",
    "                    model, tr_loader, va_loader, device, title,\n",
    "                    config=config,\n",
    "                    save_path=None  # Don't save intermediate models\n",
    "                )\n",
    "                fold_val_losses.append(val_loss)\n",
    "            except Exception as e:\n",
    "                print(f\"  [Trial {trial.number}] Fold {fold_idx} failed: {e}\")\n",
    "                fold_val_losses.append(float('inf'))\n",
    "\n",
    "            # Clean up\n",
    "            del model, tr_dataset, va_dataset, tr_loader, va_loader\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        # Return mean validation loss across all folds\n",
    "        mean_val_loss = np.mean(fold_val_losses)\n",
    "        print(f\"  [Trial {trial.number}] Mean CV loss: {mean_val_loss:.4f}\")\n",
    "        return mean_val_loss\n",
    "\n",
    "    # Run Optuna optimization\n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        study_name=f\"{data_name}_{title}_cv_opt\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=42)\n",
    "    )\n",
    "\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\n{'='*10}\")\n",
    "    print(f\"CV OPTIMIZATION COMPLETE\")\n",
    "    print(f\"{'='*10}\")\n",
    "    print(f\"Best trial: {study.best_trial.number}\")\n",
    "    print(f\"Best CV loss: {study.best_value:.6f}\")\n",
    "    print(f\"Best hyperparameters:\")\n",
    "    for key, value in study.best_params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "    return study.best_params\n",
    "\n",
    "def evaluate_model(model, dataset, device, batch_size, title, data_name):\n",
    "    '''\n",
    "    Evaluate model on a dataset and compute RMSE, Pearson, and FID metrics.\n",
    "    '''\n",
    "    model.eval()\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=False,\n",
    "        collate_fn=pad_collate, num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    rmse_list = []\n",
    "    all_ypred_pixels, all_ytrue_pixels = [], []\n",
    "\n",
    "    # Create temp directories for FID computation\n",
    "    with tempfile.TemporaryDirectory() as pred_dir, tempfile.TemporaryDirectory() as true_dir:\n",
    "        idx_img = 0\n",
    "\n",
    "        with torch.no_grad(), autocast(device_type='cuda', enabled=True):\n",
    "            for x, y, original_sizes in test_loader:\n",
    "                x = x.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True)\n",
    "\n",
    "                yhat = model(x)\n",
    "\n",
    "                B, _, H, W = y.shape\n",
    "                yhat_cropped = yhat[:, :, :H, :W].clamp(0, 1)\n",
    "\n",
    "                # RMSE\n",
    "                mse_val = F.mse_loss(yhat_cropped, y).item()\n",
    "                rmse_list.append(np.sqrt(mse_val))\n",
    "\n",
    "                # Pearson - accumulate pixels\n",
    "                yhat_flat = yhat_cropped.detach().cpu().numpy().ravel()\n",
    "                y_flat = y.detach().cpu().numpy().ravel()\n",
    "                all_ypred_pixels.append(yhat_flat)\n",
    "                all_ytrue_pixels.append(y_flat)\n",
    "\n",
    "                # FID - save normalized RGB versions\n",
    "                if yhat_cropped.shape[1] == 1:\n",
    "                    y_true_img = y.repeat(1, 3, 1, 1).float()\n",
    "                    y_pred_img = yhat_cropped.repeat(1, 3, 1, 1).float()\n",
    "                else:\n",
    "                    y_true_img, y_pred_img = y.float(), yhat_cropped.float()\n",
    "\n",
    "                # Per-image min-max to [0,1]\n",
    "                for b in range(y_true_img.size(0)):\n",
    "                    gt = y_true_img[b]\n",
    "                    pr = y_pred_img[b]\n",
    "\n",
    "                    gt = (gt - gt.min()) / (gt.max() - gt.min() + 1e-8)\n",
    "                    pr = (pr - pr.min()) / (pr.max() - pr.min() + 1e-8)\n",
    "\n",
    "                    gt_np = gt.permute(1, 2, 0).cpu().numpy()\n",
    "                    pr_np = pr.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "                    # Resize to 512x512x3 and save uint8\n",
    "                    gt_np = skimage.transform.resize(gt_np, (512, 512, 3), anti_aliasing=True, mode='reflect')\n",
    "                    pr_np = skimage.transform.resize(pr_np, (512, 512, 3), anti_aliasing=True, mode='reflect')\n",
    "\n",
    "                    gt_u8 = (gt_np * 255).clip(0, 255).astype(np.uint8)\n",
    "                    pr_u8 = (pr_np * 255).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "                    imageio.imwrite(os.path.join(true_dir, f\"{idx_img}.png\"), gt_u8)\n",
    "                    imageio.imwrite(os.path.join(pred_dir, f\"{idx_img}.png\"), pr_u8)\n",
    "                    idx_img += 1\n",
    "\n",
    "        # Compute FID\n",
    "        fid_val = fid.compute_fid(pred_dir, true_dir, mode=\"clean\", verbose=False)\n",
    "\n",
    "    # Compute final metrics\n",
    "    all_ypred_pixels = np.concatenate(all_ypred_pixels)\n",
    "    all_ytrue_pixels = np.concatenate(all_ytrue_pixels)\n",
    "    pearson_val, _ = pearsonr(all_ypred_pixels, all_ytrue_pixels)\n",
    "    rmse_mean = float(np.mean(rmse_list))\n",
    "\n",
    "    return {\n",
    "        'marker': title,\n",
    "        'rmse': rmse_mean,\n",
    "        'pearson': float(pearson_val),\n",
    "        'fid': float(fid_val)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61e1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========\n",
      "Processing: ERa (Marker 1/3)\n",
      "==========\n",
      "\n",
      "[init] Loaded train/test split from /cv_cache/train_test_split_danenberg2022_ERa.pkl\n",
      "[split] Train: 595, Test: 199\n",
      "[init] Loaded preprocessing from /cv_cache/final_preproc_danenberg2022_ERa.pkl\n",
      "[training] Training final model\n",
      "Epoch   1 | Train 0.118 | Val 0.369\n",
      "  ↳ New best val=0.369 at epoch 1\n",
      "  ↳ Saved checkpoint to /cv_cache/final_model_danenberg2022_ERa.pth\n",
      "Epoch   2 | Train 0.142 | Val 0.249\n",
      "  ↳ New best val=0.249 at epoch 2\n",
      "  ↳ Saved checkpoint to /cv_cache/final_model_danenberg2022_ERa.pth\n"
     ]
    }
   ],
   "source": [
    "dataset = \"danenberg2022\"\n",
    "path = yuvalsamoilov_danenberg2022_path\n",
    "control = [0,37,38] #histone_h3, dna1, dna2\n",
    "\n",
    "marker_tasks = [\n",
    "    (\"ERa\", 25, control),\n",
    "    (\"HER2_3b5\", 12, control),\n",
    "    (\"HER2_d8f12\", 19, control),\n",
    "]\n",
    "\n",
    "for idx, (title, target_idx, control_markers_indices) in enumerate(marker_tasks):\n",
    "    start_time = time.time()\n",
    "    print(f\"\\n{'='*10}\")\n",
    "    print(f\"Processing: {title} (Marker {idx+1}/{len(marker_tasks)})\")\n",
    "    print(f\"{'='*10}\\n\")\n",
    "    \n",
    "    result = main(\n",
    "        path=path,\n",
    "        target_idx=target_idx,\n",
    "        control_markers_indices=control_markers_indices,\n",
    "        title=title,\n",
    "        data_name=dataset,\n",
    "        cache_dir=WORK_CACHE_ROOT,\n",
    "        n_splits=3,\n",
    "        batch_size=2,\n",
    "        n_components=3,\n",
    "        cofactor=5.0,\n",
    "        finetune = False\n",
    "    )\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"--Total training time for {title}: {total_time/60:.2f} minutes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
