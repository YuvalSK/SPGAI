{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13017848,"sourceType":"datasetVersion","datasetId":8241949},{"sourceId":13018817,"sourceType":"datasetVersion","datasetId":8242635}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Stained area per marker (before/after normalization)\nThis notebook computes how much of each marker channel is 'stained' (area fraction of pixels above a threshold)\nbefore and after the **same control-marker regression normalization** used in preprocessing.\n\nOutput: one table with **mean / std / median stained area** for each **shared marker** in each dataset.\n","metadata":{}},{"cell_type":"code","source":"!pip install imagecodecs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T16:13:29.612260Z","iopub.execute_input":"2025-12-21T16:13:29.612619Z","iopub.status.idle":"2025-12-21T16:13:32.659190Z","shell.execute_reply.started":"2025-12-21T16:13:29.612592Z","shell.execute_reply":"2025-12-21T16:13:32.658471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, glob, gc, json\nimport numpy as np\nimport pandas as pd\nimport imagecodecs\nimport tifffile\nimport zipfile\nfrom sklearn.linear_model import SGDRegressor\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nDATASET_A_NAME = \"jackson2020\"\nDATASET_A_PATH = f\"/kaggle/input/{DATASET_A_NAME}\"   \n\nDATASET_B_NAME = \"danenberg2022\"\nDATASET_B_PATH = f\"/kaggle/input/{DATASET_B_NAME}\"  \n\nMARKER_NAMES_A = ['c_erb_b_2_her2', 'c_myc', 'carbonic_anhydrase_ix', 'cd20', 'cd3', 'cd44', 'cd45', 'cd68', 'cleaved_parp', 'cytokeratin_19', 'cytokeratin_5', 'cytokeratin_7', 'cytokeratin_8_18', 'dna1', 'dna2', 'e_cadherin_p_cadherin', 'egfr', 'fibronectin', 'gata3', 'histone_h3', 'histone_h3_phospho', 'histone_h3_trimethylate', 'keratin_14_krt14', 'ki_67', 'm_tor', 'p53', 'pan_cytokeratin', 'progesterone_receptor_a_b', 'rabbit_ig_g_h_l', 's6', 'slug', 'sma', 'twist', 'v_wf', 'vimentin']\nMARKER_NAMES_B = ['beta_2_microglobulin', 'c_erb_b_2_her2_3b5', 'c_erb_b_2_her2_d8f12', 'caveolin_1', 'cd11c', 'cd134', 'cd140b_pdgf_receptor_beta', 'cd15', 'cd16', 'cd163', 'cd20', 'cd278_icos', 'cd279_pd_1', 'cd3', 'cd31_v_wf', 'cd38', 'cd4', 'cd45', 'cd45ra', 'cd57', 'cd68', 'cd8a', 'cleaved_caspase3', 'cxcl12_sdf_1', 'cytokeratin_5', 'cytokeratin_8_18', 'dna1', 'dna2', 'estrogen_receptor_alpha', 'foxp3', 'fsp1', 'gitr_tnfrsf18', 'histone_h3', 'hla_abc', 'hla_dr', 'ki_67', 'pan_cytokeratin', 'podoplanin', 'sma']\n\n\nCOFACTOR = 5.0\nCHUNK_SIZE = 100_000         # for regression fitting & area computation\nSTAIN_THRESHOLD_RAW = 0.0        # threshold to define \"stained\" pixels (applied to raw and normalized values)\nRIDGE_LAMBDA = 1e-6\n\nCONTROL_MARKER_NAMES = ['dna1', 'dna2', 'histone_h3'] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T16:13:32.661095Z","iopub.execute_input":"2025-12-21T16:13:32.661372Z","iopub.status.idle":"2025-12-21T16:13:33.206727Z","shell.execute_reply.started":"2025-12-21T16:13:32.661345Z","shell.execute_reply":"2025-12-21T16:13:33.206152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def list_tiff_files(root: str):\n    files = sorted(\n        glob.glob(os.path.join(root, \"**\", \"*.tif\"), recursive=True)\n        + glob.glob(os.path.join(root, \"**\", \"*.tiff\"), recursive=True)\n    )\n    return [f for f in files if os.path.isfile(f)]\n\ndef safe_imread(path: str):\n    \"\"\"Robust TIFF reader (handles most IMC/OME-TIFF setups).\"\"\"\n    import tifffile\n    try:\n        return tifffile.imread(path)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to read TIFF: {path}\\n{e}\")\n\ndef to_hwc(img: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Ensure HWC float32.\n    Common TIFF layouts:\n      - HWC already\n      - CHW (channels first)\n      - HW (single channel)\n    \"\"\"\n    if img.ndim == 2:\n        img = img[..., None]\n    if img.ndim != 3:\n        raise ValueError(f\"Expected 2D or 3D image, got shape={img.shape}\")\n\n    # Heuristic: if first dim is \"small\", treat as channels-first\n    if img.shape[0] < img.shape[1] and img.shape[0] < img.shape[2]:\n        img = np.transpose(img, (1, 2, 0))\n\n    return img.astype(np.float32, copy=False)\n\n# ----------------------------\n# Marker indexing / validation\n# ----------------------------\n\ndef make_index_map(marker_names):\n    return {name: i for i, name in enumerate(marker_names)}\n\ndef validate_controls(marker_names, control_marker_names):\n    name_to_idx = make_index_map(marker_names)\n    missing = [c for c in control_marker_names if c not in name_to_idx]\n    if missing:\n        raise ValueError(\n            f\"Missing control markers: {missing}\\n\"\n            f\"Available markers (first 25): {marker_names[:25]}\"\n        )\n    ctrl_idx = [name_to_idx[c] for c in control_marker_names]\n    return ctrl_idx, name_to_idx\n\n# ----------------------------\n# Core computation\n# ----------------------------\n\ndef fit_controls_to_all_markers_multitarget(\n    files,\n    marker_names,\n    control_marker_names,\n    chunk_size=100_000,\n    ridge_lambda=1e-6,\n):\n    \"\"\"\n    Fit multi-target linear regression in raw space:\n      Y_nonctrl â‰ˆ [1, X_controls] @ B\n\n    Returns:\n      ctrl_idx: list[int] indices of control markers in channel axis\n      coef_full: (n_ctrl, C) float32 -- zeros for control columns\n      intercept_full: (C,) float32   -- zeros for control columns\n    \"\"\"\n    ctrl_idx, _ = validate_controls(marker_names, control_marker_names)\n    C = len(marker_names)\n    k = len(ctrl_idx)\n\n    nonctrl_idx = [i for i in range(C) if i not in ctrl_idx]\n    m = len(nonctrl_idx)\n\n    # normal equations stats for X_aug = [1, X_controls]\n    XtX = np.zeros((k + 1, k + 1), dtype=np.float64)\n    XtY = np.zeros((k + 1, m), dtype=np.float64)\n\n    for i, f in enumerate(files):\n        if i % max(1, len(files)//5) == 0 or i == len(files) - 1:\n            print(f\"[fit {os.path.basename(files[0])[:0]}] {i+1}/{len(files)}: {os.path.basename(f)}\")\n\n        img = to_hwc(safe_imread(f))\n        H, W, C_img = img.shape\n        if C_img != C:\n            raise ValueError(\n                f\"Channel mismatch in {f}:\\n\"\n                f\"  image channels={C_img}\\n\"\n                f\"  marker_names={C}\"\n            )\n\n        flat = img.reshape(-1, C_img)\n        N = flat.shape[0]\n\n        for s in range(0, N, chunk_size):\n            e = min(N, s + chunk_size)\n            chunk = flat[s:e]  # (b, C)\n\n            X = chunk[:, ctrl_idx].astype(np.float64, copy=False)  # (b, k)\n            ones = np.ones((X.shape[0], 1), dtype=np.float64)\n            X_aug = np.concatenate([ones, X], axis=1)              # (b, k+1)\n\n            Y = chunk[:, nonctrl_idx].astype(np.float64, copy=False)  # (b, m)\n\n            XtX += X_aug.T @ X_aug\n            XtY += X_aug.T @ Y\n\n        del img, flat\n        gc.collect()\n\n    XtX_reg = XtX + ridge_lambda * np.eye(k + 1, dtype=np.float64)\n    B = np.linalg.solve(XtX_reg, XtY)  # (k+1, m)\n\n    intercept = B[0, :]   # (m,)\n    coef = B[1:, :]       # (k, m)\n\n    # Expand to full marker space; controls get 0 correction\n    coef_full = np.zeros((k, C), dtype=np.float32)\n    intercept_full = np.zeros((C,), dtype=np.float32)\n\n    coef_full[:, nonctrl_idx] = coef.astype(np.float32)\n    intercept_full[nonctrl_idx] = intercept.astype(np.float32)\n\n    return ctrl_idx, coef_full, intercept_full\n\ndef compute_means_raw_and_norm_and_raw_area(\n    files,\n    marker_names,\n    ctrl_idx,\n    coef_full,\n    intercept_full,\n    chunk_size=100_000,\n    stain_threshold_raw=0.0,\n):\n    \"\"\"\n    For ALL markers:\n      - raw_mean: mean(raw) per image\n      - norm_mean: mean(resid) per image, resid = raw - pred_from_controls\n      - raw_area_%: % pixels where raw > stain_threshold_raw\n                    (computed BEFORE arcsinh and BEFORE normalization)\n    \"\"\"\n    C = len(marker_names)\n\n    raw_means = []\n    norm_means = []\n    raw_areas = []\n\n    for i, f in enumerate(files):\n        if i % max(1, len(files)//5) == 0 or i == len(files) - 1:\n            print(f\"[summaries] {i+1}/{len(files)}: {os.path.basename(f)}\")\n\n        img = to_hwc(safe_imread(f))\n        H, W, C_img = img.shape\n        if C_img != C:\n            raise ValueError(\n                f\"Channel mismatch in {f}:\\n\"\n                f\"  image channels={C_img}\\n\"\n                f\"  marker_names={C}\"\n            )\n\n        flat = img.reshape(-1, C_img)\n        N = flat.shape[0]\n\n        sum_raw = np.zeros((C,), dtype=np.float64)\n        sum_norm = np.zeros((C,), dtype=np.float64)\n        cnt_stain_raw = np.zeros((C,), dtype=np.int64)\n\n        for s in range(0, N, chunk_size):\n            e = min(N, s + chunk_size)\n            chunk = flat[s:e]  # (b, C)\n\n            # RAW mean (no arcsinh)\n            sum_raw += chunk.sum(axis=0)\n\n            # RAW stained area (no arcsinh, no normalization)\n            cnt_stain_raw += (chunk > stain_threshold_raw).sum(axis=0)\n\n            # Normalization residuals (raw space)\n            X = chunk[:, ctrl_idx]                          # (b, k)\n            pred = (X @ coef_full) + intercept_full         # (b, C)\n            resid = chunk - pred                            # (b, C)\n            sum_norm += resid.sum(axis=0)\n\n        raw_means.append(sum_raw / N)\n        norm_means.append(sum_norm / N)\n        raw_areas.append((cnt_stain_raw / N) * 100.0)\n\n        del img, flat\n        gc.collect()\n\n    raw_mean_df = pd.DataFrame(np.vstack(raw_means), columns=marker_names)\n    norm_mean_df = pd.DataFrame(np.vstack(norm_means), columns=marker_names)\n    raw_area_df = pd.DataFrame(np.vstack(raw_areas), columns=marker_names)\n\n    return raw_mean_df, norm_mean_df, raw_area_df\n\n# ----------------------------\n# Reporting\n# ----------------------------\n\ndef plot_spearman_corr_matrix(df_means: pd.DataFrame, title: str, out_png: str):\n    corr = df_means.corr(method=\"spearman\")\n    n = corr.shape[0]\n\n    # dynamic figure sizing; large marker panels get huge quickly\n    size = max(7.0, min(22.0, 0.40 * n))\n    plt.figure(figsize=(size, size))\n    im = plt.imshow(corr.values, cmap=\"coolwarm\", vmin=-1, vmax=1)\n    plt.title(title)\n\n    if n <= 60:\n        fs = max(5, int(14 - n / 5))\n        plt.xticks(range(n), corr.columns.tolist(), rotation=90, fontsize=fs)\n        plt.yticks(range(n), corr.index.tolist(), fontsize=fs)\n    else:\n        k = int(np.ceil(n / 40))\n        ticks = list(range(0, n, k))\n        plt.xticks(ticks, [corr.columns[i] for i in ticks], rotation=90, fontsize=6)\n        plt.yticks(ticks, [corr.index[i] for i in ticks], fontsize=6)\n\n    plt.colorbar(im, fraction=0.046, pad=0.04)\n    plt.tight_layout()\n    plt.savefig(out_png, dpi=200)\n    plt.close()\n    print(f\"Saved: {out_png}\")\n    return corr\n\ndef summarize_raw_area(raw_area_df: pd.DataFrame):\n    rows = []\n    for m in raw_area_df.columns:\n        v = raw_area_df[m].to_numpy(dtype=np.float64)\n        n = int(np.sum(~np.isnan(v)))\n        rows.append({\n            \"marker\": m,\n            \"n_images\": n,\n            \"raw_area_mean_%\": float(np.nanmean(v)) if n else np.nan,\n            \"raw_area_std_%\": float(np.nanstd(v, ddof=1)) if n > 1 else (0.0 if n == 1 else np.nan),\n            \"raw_area_median_%\": float(np.nanmedian(v)) if n else np.nan,\n            \"raw_area_q25_%\": float(np.nanpercentile(v, 25)) if n else np.nan,\n            \"raw_area_q75_%\": float(np.nanpercentile(v, 75)) if n else np.nan,\n        })\n    return pd.DataFrame(rows).sort_values(\"marker\").reset_index(drop=True)\n\ndef run_dataset(dataset_path, dataset_name, marker_names):\n    files = list_tiff_files(dataset_path)\n    if len(files) == 0:\n        raise ValueError(f\"No TIFF files found under: {dataset_path}\")\n\n    print(f\"\\n=== {dataset_name} ===\")\n    print(f\"Found {len(files)} TIFFs\")\n    print(f\"Markers: {len(marker_names)}\")\n\n    # Fit models\n    ctrl_idx, coef_full, intercept_full = fit_controls_to_all_markers_multitarget(\n        files=files,\n        marker_names=marker_names,\n        control_marker_names=CONTROL_MARKER_NAMES,\n        chunk_size=CHUNK_SIZE,\n        ridge_lambda=RIDGE_LAMBDA,\n    )\n\n    # Compute per-image summaries\n    raw_mean_df, norm_mean_df, raw_area_df = compute_means_raw_and_norm_and_raw_area(\n        files=files,\n        marker_names=marker_names,\n        ctrl_idx=ctrl_idx,\n        coef_full=coef_full,\n        intercept_full=intercept_full,\n        chunk_size=CHUNK_SIZE,\n        stain_threshold_raw=STAIN_THRESHOLD_RAW,\n    )\n\n    # Spearman correlations (all markers)\n    corr_raw = plot_spearman_corr_matrix(\n        raw_mean_df,\n        title=f\"{dataset_name} Spearman (RAW means, all markers)\",\n        out_png=f\"spearman_raw_all_{dataset_name}.png\",\n    )\n    corr_norm = plot_spearman_corr_matrix(\n        norm_mean_df,\n        title=f\"{dataset_name} Spearman (NORMALIZED means, all markers)\",\n        out_png=f\"spearman_norm_all_{dataset_name}.png\",\n    )\n\n    corr_raw.to_csv(f\"spearman_raw_all_{dataset_name}.csv\")\n    corr_norm.to_csv(f\"spearman_norm_all_{dataset_name}.csv\")\n    print(f\"Saved: spearman_raw_all_{dataset_name}.csv\")\n    print(f\"Saved: spearman_norm_all_{dataset_name}.csv\")\n\n    # Raw stain area stats (before arcsinh, before norm)\n    area_stats = summarize_raw_area(raw_area_df)\n    area_stats.to_csv(f\"raw_area_stats_all_{dataset_name}.csv\", index=False)\n    print(f\"Saved: raw_area_stats_all_{dataset_name}.csv\")\n\n    return {\n        \"raw_mean_df\": raw_mean_df,\n        \"norm_mean_df\": norm_mean_df,\n        \"raw_area_df\": raw_area_df,\n        \"corr_raw\": corr_raw,\n        \"corr_norm\": corr_norm,\n        \"area_stats\": area_stats,\n    }\n\ndef main():\n    # Basic safety: ensure marker lists are filled\n    if not MARKER_NAMES_A or not MARKER_NAMES_B:\n        raise ValueError(\n            \"Please paste MARKER_NAMES_A and MARKER_NAMES_B lists (must match TIFF channel order).\"\n        )\n\n    outA = run_dataset(DATASET_A_PATH, DATASET_A_NAME, MARKER_NAMES_A)\n    outB = run_dataset(DATASET_B_PATH, DATASET_B_NAME, MARKER_NAMES_B)\n\n    # Optional: print a quick peek\n    print(\"\\n--- Example outputs ---\")\n    print(outA[\"area_stats\"].head(10).to_string(index=False))\n    print(outB[\"area_stats\"].head(10).to_string(index=False))\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-21T16:13:33.207733Z","iopub.execute_input":"2025-12-21T16:13:33.208197Z","iopub.status.idle":"2025-12-21T16:28:57.086722Z","shell.execute_reply.started":"2025-12-21T16:13:33.208148Z","shell.execute_reply":"2025-12-21T16:28:57.086061Z"}},"outputs":[],"execution_count":null}]}