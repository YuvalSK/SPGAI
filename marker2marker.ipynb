{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13011054,"sourceType":"datasetVersion","datasetId":8237369},{"sourceId":13011085,"sourceType":"datasetVersion","datasetId":8237393},{"sourceId":13017848,"sourceType":"datasetVersion","datasetId":8241949},{"sourceId":13018817,"sourceType":"datasetVersion","datasetId":8242635}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"A simplefied architecture for stain 2 stain translation with leave one marker out. The input are images with varying numbers of channels (panel markers differ by study). The input is being reducted to 3D to fit to a Resnet50 encoder. The embeddings are being fed to a U-Net decoder. ","metadata":{}},{"cell_type":"markdown","source":"# imports","metadata":{}},{"cell_type":"code","source":"!pip install pytorch_msssim\n!pip install imagecodecs\n!pip install torchmetrics\n!pip install torch-fidelity","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-25T07:20:27.088320Z","iopub.execute_input":"2025-09-25T07:20:27.088541Z","iopub.status.idle":"2025-09-25T07:21:53.483708Z","shell.execute_reply.started":"2025-09-25T07:20:27.088518Z","shell.execute_reply":"2025-09-25T07:21:53.482746Z"}},"outputs":[{"name":"stdout","text":"Collecting pytorch_msssim\n  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pytorch_msssim) (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->pytorch_msssim)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->pytorch_msssim)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->pytorch_msssim)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->pytorch_msssim)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->pytorch_msssim)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->pytorch_msssim)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->pytorch_msssim)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->pytorch_msssim)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->pytorch_msssim)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->pytorch_msssim)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pytorch_msssim) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pytorch_msssim) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pytorch_msssim) (3.0.2)\nDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch_msssim\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_msssim-1.0.0\nCollecting imagecodecs\n  Downloading imagecodecs-2025.8.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imagecodecs) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->imagecodecs) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->imagecodecs) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->imagecodecs) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->imagecodecs) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->imagecodecs) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->imagecodecs) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->imagecodecs) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->imagecodecs) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->imagecodecs) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->imagecodecs) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->imagecodecs) (2024.2.0)\nDownloading imagecodecs-2025.8.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (26.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: imagecodecs\nSuccessfully installed imagecodecs-2025.8.2\nRequirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.3)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (25.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics) (2024.2.0)\nCollecting torch-fidelity\n  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (11.2.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (1.15.3)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (0.21.0+cu124)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-fidelity) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-fidelity) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-fidelity) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-fidelity) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-fidelity) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-fidelity) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-fidelity) (2024.2.0)\nDownloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\nInstalling collected packages: torch-fidelity\nSuccessfully installed torch-fidelity-0.3.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport psutil\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport tifffile\nimport zipfile\nimport imagecodecs\nimport gc\nimport time\nimport glob\nfrom collections import Counter, OrderedDict\nimport cv2\nimport random\nfrom scipy.stats import pearsonr\nfrom sklearn.decomposition import PCA, IncrementalPCA\nfrom sklearn.linear_model import LinearRegression, SGDRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import r2_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.utils.parametrizations import weight_norm\nfrom torch.utils.data import TensorDataset, DataLoader, random_split, Dataset\nfrom torch.amp import GradScaler, autocast\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom torchvision import models\nfrom pytorch_msssim import ssim\nfrom tqdm import tqdm\nimport torchvision.utils as vutils\nfrom torchmetrics.image.fid import FrechetInceptionDistance\n\nimport matplotlib.pyplot as plt\nparams = {'axes.titlesize': 30,\n          'legend.fontsize': 16,\n          'figure.figsize': (16, 10),\n          'axes.labelsize': 16,\n          'axes.titlesize': 12,\n          'xtick.labelsize': 16,\n          'ytick.labelsize': 16,\n          'figure.titlesize': 30}\n\nplt.rcParams.update(params)\nplt.style.use('seaborn-v0_8-whitegrid')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T07:21:53.485717Z","iopub.execute_input":"2025-09-25T07:21:53.485941Z","iopub.status.idle":"2025-09-25T07:22:04.920259Z","shell.execute_reply.started":"2025-09-25T07:21:53.485919Z","shell.execute_reply":"2025-09-25T07:22:04.919708Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n#print(device)\n#print(torch.cuda.get_device_name(0))\n#print(f\"Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n#print(f\"Cached: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB\")\n#print(f\"Max allocated: {torch.cuda.max_memory_allocated(0)/1024**2:.2f} MB\")\n#!free -h","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T07:22:04.923341Z","iopub.execute_input":"2025-09-25T07:22:04.923558Z","iopub.status.idle":"2025-09-25T07:22:04.999915Z","shell.execute_reply.started":"2025-09-25T07:22:04.923540Z","shell.execute_reply":"2025-09-25T07:22:04.998949Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# functions","metadata":{}},{"cell_type":"code","source":"def to_hwc(img):\n    if img.ndim == 2:\n        img = img[..., None]\n    if img.shape[0] < img.shape[1] and img.shape[0] < img.shape[2]:\n        img = np.transpose(img, (1, 2, 0))\n    return img.astype(np.float32, copy=False)\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\ndef load_model(model, path):\n    state_dict = torch.load(path)\n    # If data parallel wrapper, keys start with 'module.'\n    if list(state_dict.keys())[0].startswith(\"module.\"):\n        # Remove 'module.' prefix from all keys:\n        new_state_dict = OrderedDict()\n        for k, v in state_dict.items():\n            new_key = k.replace(\"module.\", \"\")\n            new_state_dict[new_key] = v\n        model.load_state_dict(new_state_dict)\n    else:\n        model.load_state_dict(state_dict)\n    return model\n    \ndef fit_preprocessing(\n    train_files,\n    target_idx,\n    control_markers_indices,\n    n_components=3,\n    batch_size=100_000,\n    cofactor=5.0,\n    eps=1e-8,\n):\n    \"\"\"\n    Fit channel-wise regressions and incremental PCA on residuals from IMC training images with lazy loading.\n    Returns: (regression_models, pca, pca_mean, pca_std, input_channels)\n    \"\"\"\n\n    # Discover channel setup from the first image\n    input_channels = []\n    img0 = to_hwc(tifffile.imread(train_files[0]))\n    print(f\"......example image shape: {img0.shape}\")\n    H, W, C = img0.shape\n    input_channels = [c for c in range(C) if c != target_idx and c not in control_markers_indices]\n    K = len(input_channels)\n    del img0; gc.collect()\n\n    if not input_channels:\n        print(f\"Warning: no inputs for target {target_idx} with controls {control_markers_indices}.\")\n        return None, None, None, None, input_channels\n\n    # 1. Fit regressions with SGDRegressor (partial_fit: true \"streaming\" mode)\n    regression_models = {}\n    first_pass = {}\n\n    for j in input_channels:\n        regression_models[j] = SGDRegressor(max_iter=1000, tol=1e-3)\n        first_pass[j] = True\n\n    for c, f in enumerate(train_files):\n        if c % int(len(train_files)/2) == 0 or c == len(train_files)-1:\n            print(f\"......extracting control and trg markers: {c+1} / {len(train_files)}\")\n        img = to_hwc(tifffile.imread(f))\n        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n        for j in input_channels:\n            y = img[..., j].reshape(-1)\n            if first_pass[j]:\n                regression_models[j].partial_fit(Xc, y)\n                first_pass[j] = False\n            else:\n                regression_models[j].partial_fit(Xc, y)\n        del img, Xc, y; gc.collect()\n\n    # 2. Incremental PCA on residuals (streamed, as before)\n    if n_components > K:\n        print(f\"n_components {n_components} > residual dim {K}; using {K}.\")\n        n_components = K\n    pca = IncrementalPCA(n_components=n_components)\n\n    for c, f in enumerate(train_files):\n        if c % int(len(train_files)/2) == 0 or c == len(train_files):\n            print(f\"......fitting regression: {c+1} / {len(train_files)}\")\n\n        img = to_hwc(tifffile.imread(f))\n        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n        R = np.empty((Xc.shape[0], K), dtype=np.float32)\n        for k, j in enumerate(input_channels):\n            y = img[..., j].reshape(-1)\n            y_pred = regression_models[j].predict(Xc)\n            R[:, k] = y - y_pred.astype(np.float32, copy=False)\n        R = np.arcsinh(R / cofactor, dtype=np.float32)\n        for s in range(0, R.shape[0], batch_size):\n            batch = R[s : s + batch_size]\n            pca.partial_fit(batch)\n        del img, Xc, R; gc.collect()\n\n    # 3. Compute mean/std of PCA space (streamed)\n    total = 0\n    sum_z = np.zeros(n_components, dtype=np.float64)\n    sumsq_z = np.zeros(n_components, dtype=np.float64)\n    \n    for c, f in enumerate(train_files):\n        if c % int(len(train_files)/2) == 0 or c == len(train_files):\n            print(f\"......normalization: {c+1} / {len(train_files)}\")\n\n        img = to_hwc(tifffile.imread(f))\n        Xc = img[..., control_markers_indices].reshape(-1, len(control_markers_indices))\n        R = np.empty((Xc.shape[0], K), dtype=np.float32)\n        for k, j in enumerate(input_channels):\n            y = img[..., j].reshape(-1)\n            y_pred = regression_models[j].predict(Xc)\n            R[:, k] = y - y_pred.astype(np.float32, copy=False)\n        R = np.arcsinh(R / cofactor, dtype=np.float32)\n        for s in range(0, R.shape[0], batch_size):\n            Z = pca.transform(R[s : s + batch_size]).astype(np.float32)\n            sum_z += Z.sum(axis=0)\n            sumsq_z += (Z * Z).sum(axis=0)\n            total += Z.shape[0]\n        del img, Xc, R, Z; gc.collect()\n\n    if total == 0:\n        print(\"Warning: no residuals seen for PCA stats; using zeros/ones.\")\n        pca_mean = np.zeros(n_components, dtype=np.float32)\n        pca_std = np.ones(n_components, dtype=np.float32) * eps\n    else:\n        pca_mean = (sum_z / total).astype(np.float32)\n        var = (sumsq_z / total) - (pca_mean.astype(np.float64) ** 2)\n        pca_std = (np.sqrt(np.maximum(var, 0.0)) + eps).astype(np.float32)\n\n    # Print variance captured by PCs if possible\n    if hasattr(pca, \"explained_variance_ratio_\") and pca.explained_variance_ratio_ is not None:\n        pct = pca.explained_variance_ratio_[:n_components].sum() * 100.0\n        print(f\"......PCA projection to {n_components}D captures {pct:.2f}% variance\")\n\n    return regression_models, pca, pca_mean, pca_std, input_channels\n\ndef preprocess_image(\n    file_path,\n    target_idx,\n    control_markers_indices,\n    regression_models,\n    pca,\n    pca_mean,\n    pca_std,\n    input_channels,\n    n_components=3,\n    cofactor=5.0,\n    chunk_size=100_000\n):\n    \"\"\"\n    Load and preprocess a single IMC image lazily by:\n    - loading image,\n    - normalizing target,\n    - computing residuals from regression,\n    - arcsinh transform,\n    - PCA transform in batches,\n    - Z-score normalization of PCA features,\n    - return PyTorch tensors for model input.\n    \"\"\"\n\n    def to_hwc(img):\n        if img.ndim == 2:\n            img = img[..., None]\n        if img.shape[0] < img.shape[2] and img.shape[0] < img.shape[1]:\n            img = np.transpose(img, (1, 2, 0))\n        return img.astype(np.float32, copy=False)\n\n    img = tifffile.imread(file_path)\n    img = to_hwc(img)\n    H, W, C = img.shape\n    filename = os.path.basename(file_path)\n\n    # Normalize target channel intensities with arcsinh and min-max\n    target_data = img[..., target_idx]\n    y_arc = np.arcsinh(target_data / cofactor).astype(np.float32)\n    y_min, y_max = y_arc.min(), y_arc.max()\n    y_norm = (y_arc - y_min) / (y_max - y_min + 1e-8)\n    y_tensor = torch.from_numpy(y_norm[None, ...]).float()  # (1, H, W)\n\n    # Prepare control channel matrix\n    n_ctrl = len(control_markers_indices)\n    K = len(input_channels)\n    Xc = img[..., control_markers_indices].reshape(-1, n_ctrl)           # (N, n_ctrl)\n    Yin = np.stack([img[..., j].reshape(-1) for j in input_channels], 1)  # (N, K)\n\n    # Stack regression coef and intercept for vectorized prediction\n    B = np.stack([regression_models[j].coef_ for j in input_channels], axis=-1).astype(np.float32)  # (n_ctrl, K)\n    b = np.array([regression_models[j].intercept_ for j in input_channels], dtype=np.float32)       # (K,)\n    b = b.flatten()\n\n    # Predict residuals Y - regression(X)\n    Yhat = Xc @ B + b                                                # (N, K)\n    R = Yin - Yhat\n    R = np.arcsinh(R / cofactor).astype(np.float32)\n\n    # PCA transform in chunks, for low memory\n    N = R.shape[0]\n    Z = np.empty((N, n_components), dtype=np.float32)\n    for s in range(0, N, chunk_size):\n        e = s + chunk_size\n        Z[s:e] = pca.transform(R[s:e])\n\n    # Z-score normalize PCA components\n    Z = (Z - pca_mean) / (pca_std + 1e-8)\n    Z = Z.reshape(H, W, n_components)\n\n    # Convert PCA tensor to channel-first for PyTorch\n    x_tensor = torch.from_numpy(Z).permute(2, 0, 1).contiguous().float()  # (C, H, W)\n\n    return x_tensor, y_tensor, filename\n\n\ndef apply_preprocessing(\n    files,\n    target_idx,\n    control_markers_indices,\n    regression_models,\n    pca,\n    pca_mean,\n    pca_std,\n    input_channels,\n    n_components=3,\n    cofactor=5.0,\n    chunk_size=100_000\n):\n    X_pca_tensor, Y_norm_list, filenames = [], [], []\n    \n    for c, f in enumerate(files):\n        if c % int(len(files)/2) == 0 or c == len(files):\n            print(f\"......applying preprocessing: {c+1} / {len(files)}\")\n\n        x_tensor, y_tensor, filename = preprocess_image(\n            f, target_idx, control_markers_indices, regression_models, pca,\n            pca_mean, pca_std, input_channels, n_components, cofactor, chunk_size\n        )\n        X_pca_tensor.append(x_tensor)\n        Y_norm_list.append(y_tensor)\n        filenames.append(filename)\n    return X_pca_tensor, Y_norm_list, filenames\n    \ndef pad_collate(batch):\n    \"\"\"\n    Pads all tensors in a batch to the largest size.\n    Also returns original sizes for cropping.\n    \"\"\"\n    X_list, Y_list, original_sizes = zip(*batch)\n\n    max_H = max([x.shape[1] for x in X_list])\n    max_W = max([x.shape[2] for x in X_list])\n\n    padded_X_list = []\n    padded_Y_list = []\n\n    for x_tensor, y_tensor in zip(X_list, Y_list):\n        pad_H = max_H - x_tensor.shape[1]\n        pad_W = max_W - x_tensor.shape[2]\n\n        padded_X = F.pad(x_tensor, (0, pad_W, 0, pad_H))\n        padded_Y = F.pad(y_tensor, (0, pad_W, 0, pad_H))\n\n        padded_X_list.append(padded_X)\n        padded_Y_list.append(padded_Y)\n\n\n    return torch.stack(padded_X_list), torch.stack(padded_Y_list), original_sizes\n\ndef train_model(model, train_loader, val_loader, device, title,\n                epochs=50, \n                lr=1e-3, \n                alpha=0.8,          # weight for Huber; (1 - alpha) for SSIM\n                huber_beta=1.0,     \n                grad_clip=1.0,\n                use_amp=True,\n                patience=10, \n                save_path=\"best_model.pth\",\n                dataset=None):\n\n    \"\"\"\n    Loss = alpha * Huber(y_hat, y) + (1 - alpha) * (1 - SSIM(y_hat_norm, y_norm)).\n    - Huber is on intensities.\n    - SSIM is per-image min-max normalized to [0,1].\n    \"\"\"\n\n    model.to(device)\n    \n    save_path = datsset+\"_\"+title+\"_\"+save_path\n    \n    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode=\"min\", factor=0.5, patience=3) #change, was 3\n    scaler = GradScaler(enabled=use_amp)\n\n    train_losses, val_losses = [], []\n    best_val, best_state, best_epoch = float(\"inf\"), None, None\n    no_improve = 0\n    epsilon = 1e-8\n\n    for epoch in range(epochs):\n        # Training loop unchanged\n        model.train()\n        running = 0.0\n        for x, y, original_sizes in train_loader:\n            x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n            B, _, H_padded, W_padded = x.shape  # Padded dimensions\n\n            opt.zero_grad(set_to_none=True)\n            with autocast(device_type='cuda', enabled=use_amp):\n                yhat = model(x)\n\n                hub_sum = 0.0\n                ssim_sum = 0.0\n                for i in range(B):\n                    h, w = original_sizes[i]\n                    y_i = y[i:i+1, :, :h, :w]  # Ground truth (cropped)\n                    yhat_i = yhat[i:i+1, :, :h, :w]  # Prediction (cropped)\n\n                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n                    hub_sum += hub_i\n\n                    y_min, y_max = y_i.min().detach(), y_i.max().detach()\n                    yh_min, yh_max = yhat_i.min().detach(), yhat_i.max().detach()\n                    y_n = (y_i - y_min) / (y_max - y_min + epsilon)\n                    yhat_n = (yhat_i - yh_min) / (yh_max - yh_min + epsilon)\n                    ssim_sum += (1.0 - ssim(yhat_n, y_n, data_range=1.0))\n\n                hub_mean = hub_sum / B\n                ssim_mean = ssim_sum / B\n\n                loss = alpha * hub_mean + (1 - alpha) * ssim_mean\n\n            scaler.scale(loss).backward()\n            if grad_clip is not None:\n                scaler.unscale_(opt)\n                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n            scaler.step(opt)\n            scaler.update()\n\n            running += loss.item() * B\n\n        train_loss = running / len(train_loader.dataset)\n        train_losses.append(train_loss)\n\n        # Validation loop with robust error checking and batch skipping\n        model.eval()\n        val_running = 0.0\n        valid_batches = 0\n        with torch.no_grad(), autocast(device_type='cuda', enabled=use_amp):\n            for batch_idx, (x, y, original_sizes) in enumerate(val_loader):\n                x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n                B, _, H_padded, W_padded = x.shape  # Padded dimensions\n\n                yhat = model(x)\n\n                hub_sum = 0.0\n                ssim_sum = 0.0\n                skip_batch = False\n\n                for i in range(B):\n                    h, w = original_sizes[i]\n                    y_i = y[i:i+1, :, :h, :w]\n                    yhat_i = yhat[i:i+1, :, :h, :w]\n\n                    # Clamp predictions between 0 and 1 for numerical stability\n                    yhat_i = torch.clamp(yhat_i, min=0.0, max=1.0)\n\n                    y_min, y_max = y_i.min(), y_i.max()\n                    yh_min, yh_max = yhat_i.min(), yhat_i.max()\n                    denom_y = (y_max - y_min).abs() + epsilon\n                    denom_yh = (yh_max - yh_min).abs() + epsilon\n\n                    if denom_y < epsilon or denom_yh < epsilon:\n                        #print(f\"Note: validation batch {batch_idx}, sample {i} skipped due to near-constant values\")\n                        skip_batch = True\n                        break\n\n                    y_n = (y_i - y_min) / denom_y\n                    yhat_n = (yhat_i - yh_min) / denom_yh\n\n                    ssim_val = ssim(yhat_n, y_n, data_range=1.0)\n                    if torch.isnan(ssim_val) or torch.isinf(ssim_val):\n                        #print(f\"Note: validation batch {batch_idx}, sample {i} SSIM returned NaN or Inf, skipping batch\")\n                        skip_batch = True\n                        break\n\n                    hub_i = F.smooth_l1_loss(yhat_i, y_i, beta=huber_beta, reduction=\"mean\")\n                    if torch.isnan(hub_i) or torch.isinf(hub_i):\n                        #print(f\"Note: validation batch {batch_idx}, sample {i} Huber loss returned NaN or Inf, skipping batch\")\n                        skip_batch = True\n                        break\n\n                    hub_sum += hub_i\n                    ssim_sum += (1.0 - ssim_val)\n\n                if skip_batch:\n                    continue  # Skip entire batch aggregation\n\n                val_loss_batch = (alpha * hub_sum + (1 - alpha) * ssim_sum) / B\n                if torch.isnan(val_loss_batch) or torch.isinf(val_loss_batch):\n                    #print(f\"Note: validation batch {batch_idx} computed val_loss_batch as NaN or Inf, skipping\")\n                    continue\n\n                val_running += float(val_loss_batch) * B\n                valid_batches += B\n\n        if valid_batches > 0:\n            val_loss = val_running / valid_batches\n        else:\n            val_loss = float('nan')\n\n        val_losses.append(val_loss)\n        sched.step(val_loss)\n\n        print(f\"Epoch {epoch+1:>3d} | Train {train_loss:.3f} | Val {val_loss:.3f}\")\n\n        # ---- Early stopping ----\n        if val_loss + 1e-6 < best_val:\n            best_val, best_epoch = val_loss, epoch + 1\n            best_state = {k: v.clone() for k, v in model.state_dict().items()}\n            no_improve = 0\n            print(f\"  ↳ New best val={val_loss:.3f} at epoch {best_epoch}\")\n            if save_path:\n                torch.save(best_state, save_path)\n                print(f\"  ↳ Saved checkpoint to {save_path}\")\n        else:\n            no_improve += 1\n            print(f\"  ↳ No improvement ({no_improve}/{patience} patience)\")\n            if patience is not None and no_improve >= patience:\n                print(f\"--Early stopping at epoch {epoch+1}. Best epoch was {best_epoch} with val={best_val:.3f}\")\n                break\n\n    # Restore best weights\n    if best_state is not None:\n        model.load_state_dict(best_state)\n        print(f\"--Restored model weights from epoch {best_epoch} (val={best_val:.3f})\")\n\n    # Plot losses\n    plt.figure(figsize=(8, 5))\n    plt.plot(range(1, len(train_losses)+1), train_losses, marker='o', label='Train')\n    plt.plot(range(1, len(val_losses)+1), val_losses, marker='s', label='Val')\n    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title(f'Marker: {title}')\n    plt.legend(); plt.grid(True); plt.show()\n\n    return train_losses, val_losses\n    \ndef visualize_prediction(model, dataset, device, index=0, target_channel=0, name=\"\", show_all_channels=True, vmax=None):\n    \"\"\"\n    Visualizes ground truth for target_channel, PCA input channels grid, and model prediction.\n    The order is Ground Truth, PCA Input, Prediction as requested.\n    \"\"\"\n    model.eval()\n    x_tensor, y_tensor, _ = dataset[index]\n    x_tensor = x_tensor.unsqueeze(0).to(device)\n    y_tensor = y_tensor.unsqueeze(0).to(device)\n    with torch.no_grad():\n        y_pred = model(x_tensor)\n\n    x_img = x_tensor.squeeze().cpu()  # [C,H,W]\n    y_pred_np = y_pred.squeeze().cpu().numpy()\n    y_true_np = y_tensor.squeeze().cpu().numpy()\n\n    # Optionally clip outliers for input channels\n    for c in range(x_img.shape[0]):\n        low = torch.quantile(x_img[c], 0.01)\n        high = torch.quantile(x_img[c], 0.99)\n        x_img[c].clamp_(low, high)\n\n    # Select single target channel ground truth and prediction slice\n    # If ground truth and prediction have multiple channels, pick the target one\n    if y_true_np.ndim == 3:\n        y_true_np = y_true_np[target_channel]\n    if y_pred_np.ndim == 3:\n        y_pred_np = y_pred_np[target_channel]\n\n    # Normalize prediction & ground truth to [0,1]\n    y_pred_np = (y_pred_np - y_pred_np.min()) / (y_pred_np.max() - y_pred_np.min() + 1e-8)\n    y_true_np = (y_true_np - y_true_np.min()) / (y_true_np.max() - y_true_np.min() + 1e-8)\n\n    # Prepare PCA input visualization\n    num_channels = x_img.shape[0]\n    grid = torch.stack([x_img[c] for c in range(min(3, num_channels))])\n    x_np = grid[0].numpy() ** 0.8\n\n    # Plot in order: Ground Truth, PCA Input, Prediction\n    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n    axs[0].imshow(y_true_np, cmap='inferno')\n    axs[0].set_title(f\"Ground Truth (Ch {target_channel})\")\n    axs[0].axis(\"off\")\n\n    if grid.size(0) == 3:\n        axs[1].imshow(x_np)\n    else:\n        axs[1].imshow(x_np, cmap='gray')\n    axs[1].set_title(\"PCA Input (first 3 channels)\")\n    axs[1].axis(\"off\")\n\n    axs[2].imshow(y_pred_np, cmap='inferno')\n    axs[2].set_title(f\"Predicted (Ch {target_channel})\")\n    axs[2].axis(\"off\")\n\n    plt.suptitle(name)\n    plt.tight_layout()\n    plt.savefig(f\"Reconstruction Result - {name}.png\", dpi=400, bbox_inches=\"tight\")\n    plt.close(fig)\n\ndef plot_marker_comparison_hbar(df_A, df_B, metric=\"RMSE\", label_A=\"Dataset A\", label_B=\"Dataset B\", sort=False):\n    \"\"\"\n    metric: one of [\"RMSE\", \"PSNR\", \"Pearson\"] -> uses <metric>_mean and <metric>_std columns\n    sort: if True, markers are sorted by Dataset A values ascending; otherwise use df_A order\n    \"\"\"\n    mean_col = f\"{metric}_mean\"\n    std_col  = f\"{metric}_std\"\n\n    # Add dataset labels and combine\n    a = df_A.copy()\n    b = df_B.copy()\n    a[\"dataset\"] = label_A\n    b[\"dataset\"] = label_B\n    both = pd.concat([a, b], ignore_index=True)\n\n    # Choose marker order\n    if sort:\n        order = (a.sort_values(mean_col, ascending=True)[\"marker\"].tolist())\n    else:\n        # keep the order as it appears in df_A\n        order = a[\"marker\"].tolist()\n\n    # Pivot to get A/B columns for means and stds\n    mean_p = (both.pivot(index=\"marker\", columns=\"dataset\", values=mean_col)\n                   .reindex(order))\n    std_p  = (both.pivot(index=\"marker\", columns=\"dataset\", values=std_col)\n                   .reindex(order))\n\n    # y positions\n    markers = mean_p.index.tolist()\n    y = np.arange(len(markers))\n    h = 0.38  # bar height for each dataset\n\n    fig_h = max(4, 0.5 * len(markers) + 2)  # scale height by number of markers\n    fig, ax = plt.subplots(figsize=(10, fig_h))\n\n    # Bars (horizontal) with error bars\n    ax.barh(y - h/2, mean_p[label_A], h, xerr=std_p[label_A], label=label_A)\n    ax.barh(y + h/2, mean_p[label_B], h, xerr=std_p[label_B], label=label_B)\n\n    ax.set_yticks(y)\n    ax.set_yticklabels(markers)\n    ax.set_xlabel(metric)\n    ax.set_title(f\"{metric} comparison per marker (mean ± std)\")\n    ax.legend()\n    plt.tight_layout()\n    plt.savefig(f\"{metric}_comparison_hbar.png\", dpi=400, bbox_inches=\"tight\")\n    plt.close(fig)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T07:22:05.003588Z","iopub.execute_input":"2025-09-25T07:22:05.003827Z","iopub.status.idle":"2025-09-25T07:22:05.249609Z","shell.execute_reply.started":"2025-09-25T07:22:05.003809Z","shell.execute_reply":"2025-09-25T07:22:05.248789Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class ResNet50Encoder(nn.Module):\n    def __init__(self, in_channels=3):\n        super().__init__()\n        backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = backbone.bn1\n        self.relu = backbone.relu\n        self.maxpool = backbone.maxpool\n        self.layer1 = backbone.layer1\n        self.layer2 = backbone.layer2\n        self.layer3 = backbone.layer3\n        self.layer4 = backbone.layer4\n        for param in backbone.parameters():\n            param.requires_grad = False\n\n        #learn params of two last layer\n        for param in self.layer3.parameters():\n            param.requires_grad = True\n            \n        for param in self.layer4.parameters():\n            param.requires_grad = True\n\n    def forward(self, x):\n        f0 = self.conv1(x)\n        f0 = self.bn1(f0)\n        f0 = self.relu(f0)\n        f0_pool = self.maxpool(f0)\n        f1 = self.layer1(f0_pool)\n        f2 = self.layer2(f1)\n        f3 = self.layer3(f2)\n        f4 = self.layer4(f3)\n        return f0, f1, f2, f3, f4\n\n\nclass UNetDecoder(nn.Module):\n    def __init__(self, out_channels=1, p=0.2):\n        super().__init__()\n        # Stage f4(2048) -> f3 scale (target 1024 ch)\n        self.conv4_1 = nn.Sequential(\n            nn.Conv2d(2048 + 1024, 1024, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n        self.conv4_2 = nn.Sequential(\n            nn.Conv2d(1024, 1024, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(inplace=True),\n        )\n\n        # Stage -> f2 scale (target 512 ch)\n        self.conv3_1 = nn.Sequential(\n            nn.Conv2d(1024 + 512, 512, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n        self.conv3_2 = nn.Sequential(\n            nn.Conv2d(512, 512, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(512),\n            nn.ReLU(inplace=True),\n        )\n\n        # Stage -> f1 scale (target 256 ch)\n        self.conv2_1 = nn.Sequential(\n            nn.Conv2d(512 + 256, 256, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n        self.conv2_2 = nn.Sequential(\n            nn.Conv2d(256, 256, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n        )\n\n        # Stage -> combine (f1 + f0) at f1 scale (target 64 ch)\n        self.conv1_1 = nn.Sequential(\n            nn.Conv2d(256 + 256 + 64, 64, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Dropout2d(p),\n        )\n        self.conv1_2 = nn.Sequential(\n            nn.Conv2d(64, 64, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n        )\n\n        # Final upsample \n        self.final_up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n\n        # Light head\n        self.up0 = nn.Sequential(\n            nn.Conv2d(64, 32, 3, padding=1, padding_mode='reflect', bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n        )\n        self.final = weight_norm(nn.Conv2d(32, out_channels, 1))\n\n    def forward(self, skips):\n        f0, f1, f2, f3, f4 = skips \n\n        # ---- up4: f4 -> f3 scale ----\n        x = F.interpolate(f4, scale_factor=2, mode='bilinear', align_corners=False)\n        if x.shape[-2:] != f3.shape[-2:]:\n            f3 = F.interpolate(f3, size=x.shape[-2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, f3], dim=1)\n        x = self.conv4_1(x)\n        x = self.conv4_2(x)\n\n        # ---- up3: -> f2 scale ----\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n        if x.shape[-2:] != f2.shape[-2:]:\n            f2 = F.interpolate(f2, size=x.shape[-2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, f2], dim=1)\n        x = self.conv3_1(x)\n        x = self.conv3_2(x)\n\n        # ---- up2: -> f1 scale ----\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)\n        if x.shape[-2:] != f1.shape[-2:]:\n            f1 = F.interpolate(f1, size=x.shape[-2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, f1], dim=1)\n        x = self.conv2_1(x)\n        x = self.conv2_2(x)\n\n        # ---- up1: combine f1 & f0 at f1 scale ----\n        # f0 may need resize to f1 scale\n        if f0.shape[-2:] != f1.shape[-2:]:\n            f0 = F.interpolate(f0, size=f1.shape[-2:], mode='bilinear', align_corners=False)\n        x = torch.cat([x, f1, f0], dim=1)\n        x = self.conv1_1(x)\n        x = self.conv1_2(x)\n\n        # ---- final upsample + head ----\n        x = self.final_up(x) \n        x = self.up0(x)\n        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False) \n        x = torch.sigmoid(self.final(x))\n        return x\n\nclass ResNetUNet(nn.Module):\n    def __init__(self, in_channels=3):\n        super().__init__()\n        self.encoder = ResNet50Encoder(in_channels=in_channels)\n        self.decoder = UNetDecoder()\n\n    def forward(self, x):\n        skips = self.encoder(x)\n        return self.decoder(skips)\n\n# Wrap the lists in a custom Dataset class\nclass CustomDataset(Dataset):\n    def __init__(self, file_list, target_idx, control_markers_indices,\n                 regression_models, pca, pca_mean, pca_std, input_channels,\n                 n_components=3, cofactor=5.0, chunk_size=100_000):\n        self.file_list = file_list\n        self.target_idx = target_idx\n        self.control_markers_indices = control_markers_indices\n        self.regression_models = regression_models\n        self.pca = pca\n        self.pca_mean = pca_mean\n        self.pca_std = pca_std\n        self.input_channels = input_channels\n        self.n_components = n_components\n        self.cofactor = cofactor\n        self.chunk_size = chunk_size\n\n    def __len__(self):\n        return len(self.file_list)\n\n    def __getitem__(self, idx):\n        file_path = self.file_list[idx]\n        x_tensor, y_tensor, _ = preprocess_image(\n            file_path,\n            self.target_idx,\n            self.control_markers_indices,\n            self.regression_models,\n            self.pca,\n            self.pca_mean,\n            self.pca_std,\n            self.input_channels,\n            self.n_components,\n            self.cofactor,\n            self.chunk_size\n        )\n        H, W = x_tensor.shape[1], x_tensor.shape[2]  \n        return x_tensor, y_tensor, (H, W)\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T07:22:05.294649Z","iopub.execute_input":"2025-09-25T07:22:05.295354Z","iopub.status.idle":"2025-09-25T07:22:05.315005Z","shell.execute_reply.started":"2025-09-25T07:22:05.295335Z","shell.execute_reply":"2025-09-25T07:22:05.314332Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def main(\n    path: str,\n    target_idx: int,\n    control_markers_indices: list,\n    title: str = \"Unspecified\",\n    n_splits: int = 4,\n    batch_size: int = 4,\n    device: str = None,\n    data_name: str = None, \n) -> dict:\n    \"\"\"\n    Runs cross-validation for IMC breast cancer marker analysis with parameterized hyperparameters.\n    Args:\n        target_idx (int): Target marker index.\n        control_markers_indices (list): Control markers indices.\n        title (str): Marker name for labeling results.\n        n_splits (int): Number of cross-validation folds.\n        batch_size (int): Batch size for DataLoader.\n        device (str): Device for computation (\"cuda\", \"cpu\", or None to auto-detect).\n        data_name (str): Dataset name for visualization filename.\n    Returns:\n        dict: Aggregated mean and std metrics across folds, including averaged FID.\n    \"\"\"\n    set_seed()  # for reproducibility\n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    extract_folder = path\n    all_files = [os.path.join(extract_folder, f) for f in os.listdir(extract_folder) if f.endswith(('.tif', '.tiff'))]\n        \n    if len(all_files) < n_splits:\n        raise ValueError(f\"Number of files ({len(all_files)}) must be >= number of CV splits ({n_splits})\")\n    \n    kf = KFold(n_splits=n_splits, shuffle=True)\n    rmse_folds, pearson_folds, fid_folds = [], [], []\n    \n    best_rmse = None\n    best_fold_idx = None\n    best_model_path = None\n    best_val_files = None\n    best_reg_models = None\n    best_pca = None\n    best_pca_mean = None\n    best_pca_std = None\n    best_input_channels = None\n    \n    for fold_idx, (train_indices, val_indices) in enumerate(kf.split(all_files), 1):\n        print(f\"###### Fold {fold_idx}/{n_splits}, marker {title} ######\")\n        torch.cuda.empty_cache()\n        train_files = [all_files[i] for i in train_indices]\n        val_files = [all_files[i] for i in val_indices]\n        \n        #print(\"......running data preprocessing\")\n        reg_models, pca, pca_mean, pca_std, input_channels = fit_preprocessing(\n            train_files, target_idx, control_markers_indices\n        )\n        \n        # Prepare datasets and loaders\n        train_dataset = CustomDataset(\n            train_files, target_idx, control_markers_indices, reg_models,\n            pca, pca_mean, pca_std, input_channels\n        )\n        val_dataset = CustomDataset(\n            val_files, target_idx, control_markers_indices, reg_models,\n            pca, pca_mean, pca_std, input_channels\n        )\n    \n        train_loader = DataLoader(\n            train_dataset, batch_size=batch_size, shuffle=True,\n            collate_fn=pad_collate, num_workers=2, pin_memory=True\n        )\n        val_loader = DataLoader(\n            val_dataset, batch_size=batch_size, shuffle=False,\n            collate_fn=pad_collate, num_workers=2, pin_memory=True\n        )\n        \n        model = ResNetUNet(in_channels=3).to(device)\n        if torch.cuda.device_count() > 1:\n            print(\"......available GPUs:\", torch.cuda.device_count())\n            model = torch.nn.DataParallel(model)\n            \n        #print(\"......training\")\n        train_model(\n            model, train_loader, val_loader, device,\n            title=f\"{title} fold {fold_idx}\", dataset=data_name\n        )\n        torch.cuda.empty_cache()\n        \n        model.eval()\n        rmse_list, pearson_list = [], []\n        fid_metric = FrechetInceptionDistance(feature=2048).to(device)\n        all_y_pred = []\n        all_y_true = []\n        with torch.no_grad():\n            for x, y,_ in val_loader:\n                x, y = x.to(device), y.to(device)\n                yhat = model(x)\n                _, _, H, W = y.shape\n                yhat_cropped = yhat[:, :, :H, :W]\n                mse_val = F.mse_loss(yhat_cropped, y).item()\n                rmse_val = np.sqrt(mse_val)\n                yhat_flat = yhat_cropped.cpu().numpy().flatten()\n                y_flat = y.cpu().numpy().flatten()\n                pearson_val, _ = pearsonr(yhat_flat, y_flat)\n                rmse_list.append(rmse_val)\n                pearson_list.append(pearson_val)\n                if yhat_cropped.shape[1] == 1:\n                    y_true_img = y.repeat(1, 3, 1, 1).float()\n                    y_pred_img = yhat_cropped.repeat(1, 3, 1, 1).float()\n                else:\n                    y_true_img, y_pred_img = y.float(), yhat_cropped.float()\n                y_true_img = (y_true_img - y_true_img.min()) / (y_true_img.max() - y_true_img.min() + 1e-8)\n                y_pred_img = (y_pred_img - y_pred_img.min()) / (y_pred_img.max() - y_pred_img.min() + 1e-8)\n                all_y_pred.append(y_pred_img.cpu())\n                all_y_true.append(y_true_img.cpu())\n        for pred_img in all_y_pred:\n            img_uint8 = (pred_img * 255).clamp(0, 255).to(torch.uint8).to(device)\n            fid_metric.update(img_uint8, real=False)\n        for true_img in all_y_true:\n            img_uint8 = (true_img * 255).clamp(0, 255).to(torch.uint8).to(device)\n            fid_metric.update(img_uint8, real=True)\n        fold_rmse = np.mean(rmse_list)\n        fold_pearson = np.mean(pearson_list)\n        fold_fid = fid_metric.compute().item()\n        \n        rmse_folds.append(fold_rmse)\n        pearson_folds.append(fold_pearson)\n        fid_folds.append(fold_fid)\n        \n        # Track best fold by RMSE (lowest)\n        if best_rmse is None or fold_rmse < best_rmse:\n            best_rmse = fold_rmse\n            best_fold_idx = fold_idx\n            best_model_path = f\"best_model_{title}.pt\"\n            torch.save(model.state_dict(), best_model_path)\n            best_val_files = val_files\n            best_reg_models = reg_models\n            best_pca = pca\n            best_pca_mean = pca_mean\n            best_pca_std = pca_std\n            best_input_channels = input_channels\n    \n    print(f\"###### Done training {title}! ###### \\n Stats: RMSE = {float(np.mean(rmse_folds)):.1f} Peasrson = {float(np.mean(pearson_folds)):.1f} FID = {float(np.mean(fid_folds)):.1f}\")\n    \n    results = {\n        \"marker\": title,\n        \"RMSE_mean\": float(np.mean(rmse_folds)),\n        \"RMSE_std\": float(np.std(rmse_folds)),\n        \"Pearson_mean\": float(np.mean(pearson_folds)),\n        \"Pearson_std\": float(np.std(pearson_folds)),\n        \"FID_mean\": float(np.mean(fid_folds)),\n        \"FID_std\": float(np.std(fid_folds)),\n    }\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T07:25:36.110286Z","iopub.execute_input":"2025-09-25T07:25:36.111116Z","iopub.status.idle":"2025-09-25T07:25:36.127300Z","shell.execute_reply.started":"2025-09-25T07:25:36.111086Z","shell.execute_reply":"2025-09-25T07:25:36.126514Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# load data","metadata":{}},{"cell_type":"code","source":"dataset = \"danenberg2022\"\npath = f\"/kaggle/input/{dataset}\"\ncontrol = [0,37,38] #histone_h3, dna1, dna2\n\nmarker_tasks = [\n    #(\"ki67\", 28, control),\n    (\"sma\", 1, control),\n\n    #(\"CD3\", 13, control),\n    #(\"CD20\", 24, control),\n    #(\"CD45\", 22, control), \n    #(\"CD68\", 11, control),\n    \n    #(\"pan_cytokeratin\", 35, control), \n    #(\"cytokeratin_5\", 2, control),\n    #(\"cytokeratin_8_18\", 5, control),\n\n    #Keren 2018:\n    #(\"CD11c\", 15, control),\n    #(\"CD16\", 18, control),\n    #(\"hla_dr\", 4, control),\n]\n\nd_results = []\nfor title, target_idx, control_markers_indices in marker_tasks:\n    start_time = time.time()\n    print(f\"Analyzing {dataset} dataset\")\n    \n    res = main(path, target_idx, control_markers_indices, title=title, data_name = dataset)\n    d_results.append(res)\n    \n    df_res = pd.DataFrame([res])\n    df_res.to_csv(f\"{dataset[0]}_results_{title}_5fold.csv\", index=False)\n\n    # Reload best fold model and dataset for visualization\n    #best_val_dataset = CustomDataset(\n    #    best_val_files, target_idx, control_markers_indices,\n    #    best_reg_models, best_pca, best_pca_mean, best_pca_std, best_input_channels\n    #)\n    \n    #best_model = ResNetUNet(in_channels=3).to(device)\n    #best_model = load_model(best_model, best_model_path)\n    #best_model.eval()\n    \n    #index = 1\n    #visualize_prediction(best_model, best_val_dataset, device, index=index, target_channel=target_idx, name=f\"{data_name}_{title}_BestFold_Example\")\n    \n    total_time = time.time() - start_time\n    print(f\"--Total training time for {title}: {total_time/60:.2f} minutes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T07:25:58.317525Z","iopub.execute_input":"2025-09-25T07:25:58.318132Z"}},"outputs":[{"name":"stdout","text":"Analyzing danenberg2022 dataset\n###### Fold 1/4, marker sma ######\n......example image shape: (634, 562, 39)\n......extracting control and trg markers: 1 / 595\n......extracting control and trg markers: 298 / 595\n......extracting control and trg markers: 595 / 595\n......fitting regression: 1 / 595\n......fitting regression: 298 / 595\n......fitting regression: 595 / 595\n......normalization: 1 / 595\n......normalization: 298 / 595\n......normalization: 595 / 595\n......PCA projection to 3D captures 82.00% variance\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 192MB/s] \n","output_type":"stream"},{"name":"stdout","text":"......available GPUs: 2\nEpoch   1 | Train 0.206 | Val 0.159\n  ↳ New best val=0.159 at epoch 1\n  ↳ Saved checkpoint to best_model.pth\nEpoch   2 | Train 0.154 | Val 0.135\n  ↳ New best val=0.135 at epoch 2\n  ↳ Saved checkpoint to best_model.pth\nEpoch   3 | Train 0.131 | Val 0.140\n  ↳ No improvement (1/10 patience)\nEpoch   4 | Train 0.127 | Val 0.122\n  ↳ New best val=0.122 at epoch 4\n  ↳ Saved checkpoint to best_model.pth\nEpoch   5 | Train 0.125 | Val 0.122\n  ↳ No improvement (1/10 patience)\nEpoch   6 | Train 0.126 | Val 0.125\n  ↳ No improvement (2/10 patience)\nEpoch   7 | Train 0.129 | Val 0.145\n  ↳ No improvement (3/10 patience)\nEpoch   8 | Train 0.131 | Val 0.123\n  ↳ No improvement (4/10 patience)\nEpoch   9 | Train 0.130 | Val 0.124\n  ↳ No improvement (5/10 patience)\nEpoch  10 | Train 0.130 | Val 0.124\n  ↳ No improvement (6/10 patience)\nEpoch  11 | Train 0.130 | Val 0.136\n  ↳ No improvement (7/10 patience)\nEpoch  12 | Train nan | Val 0.123\n  ↳ No improvement (8/10 patience)\nEpoch  13 | Train 0.129 | Val 0.140\n  ↳ No improvement (9/10 patience)\nEpoch  14 | Train nan | Val 0.134\n  ↳ No improvement (10/10 patience)\n--Early stopping at epoch 14. Best epoch was 4 with val=0.122\n--Restored model weights from epoch 4 (val=0.122)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x500 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stderr","text":"Downloading: \"https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth\n100%|██████████| 91.2M/91.2M [00:00<00:00, 263MB/s]\n","output_type":"stream"},{"name":"stdout","text":"###### Fold 2/4, marker sma ######\n......example image shape: (667, 489, 39)\n......extracting control and trg markers: 1 / 595\n......extracting control and trg markers: 298 / 595\n......extracting control and trg markers: 595 / 595\n......fitting regression: 1 / 595\n......fitting regression: 298 / 595\n......fitting regression: 595 / 595\n......normalization: 1 / 595\n......normalization: 298 / 595\n......normalization: 595 / 595\n......PCA projection to 3D captures 85.80% variance\n......available GPUs: 2\nEpoch   1 | Train 0.194 | Val 0.147\n  ↳ New best val=0.147 at epoch 1\n  ↳ Saved checkpoint to best_model.pth\nEpoch   2 | Train 0.155 | Val 0.127\n  ↳ New best val=0.127 at epoch 2\n  ↳ Saved checkpoint to best_model.pth\nEpoch   3 | Train 0.134 | Val 0.118\n  ↳ New best val=0.118 at epoch 3\n  ↳ Saved checkpoint to best_model.pth\nEpoch   4 | Train 0.129 | Val 0.127\n  ↳ No improvement (1/10 patience)\nEpoch   5 | Train 0.130 | Val 0.119\n  ↳ No improvement (2/10 patience)\nEpoch   6 | Train 0.132 | Val 0.133\n  ↳ No improvement (3/10 patience)\nEpoch   7 | Train 0.129 | Val 0.124\n  ↳ No improvement (4/10 patience)\nEpoch   8 | Train 0.128 | Val 0.122\n  ↳ No improvement (5/10 patience)\nEpoch   9 | Train 0.128 | Val 0.120\n  ↳ No improvement (6/10 patience)\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"dataset = \"jackson2020\"\npath = f\"/kaggle/input/{dataset}\"\ncontrol = [0, 33, 34] #histone_h3, dna1, dna2\n\nmarker_tasks = [\n    #(\"ki67\", 25, control),\n    (\"sma\", 9, control),\n\n    #(\"CD3\", 13, control),\n    #(\"CD20\", 22, control),\n    (\"CD45\", 20, control),\n    #(\"CD68\", 7, control),\n    \n    (\"pan_cytokeratin\", 31, control),\n    (\"cytokeratin_5\", 2, control),\n    #(\"cytokeratin_8_18\", 5, control),\n]\n\nj_results = []\nfor title, target_idx, control_markers_indices in marker_tasks:\n    start_time = time.time()\n    print(f\"Analyzing {dataset} dataset\")\n    \n    res = main(path, target_idx, control_markers_indices, title=title, data_name = dataset)\n    \n    df_res = pd.DataFrame([res])\n    df_res.to_csv(f\"{dataset[0]}_results_{title}_5fold.csv\", index=False)\n\n    j_results.append(res)\n\n    total_time = time.time() - start_time\n    print(f\"--Total training time for {title}: {total_time/60:.2f} minutes\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# comparison","metadata":{}},{"cell_type":"code","source":"#load results per marker into a dataframe. add column for avg across markers. \nj_df = pd.DataFrame(j_results)\nd_df = pd.DataFrame(d_results)\nplot_marker_comparison_hbar(d_df, j_df, metric=\"RMSE\", label_A=\"Danenberg2022\", label_B=\"Jackson2020\")\nplot_marker_comparison_hbar(d_df, j_df, metric=\"Pearson\", label_A=\"Danenberg2022\", label_B=\"Jackson2020\")\nplot_marker_comparison_hbar(d_df, j_df, metric=\"FID\", label_A=\"Danenberg2022\", label_B=\"Jackson2020\")\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}